#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬¬ä¸‰é˜¶æ®µæ€§èƒ½ä¼˜åŒ–æµ‹è¯• v1.0.0
æµ‹è¯•é«˜æ€§èƒ½æ–‡ä»¶è¯»å–å™¨ã€æ¸²æŸ“æ€§èƒ½ä¼˜åŒ–å™¨ã€å†…å­˜ä¼˜åŒ–ç®¡ç†å™¨å’Œæ€§èƒ½åŸºå‡†æµ‹è¯•å™¨

ä½œè€…: LAD Team
åˆ›å»ºæ—¶é—´: 2025-08-16
æœ€åæ›´æ–°: 2025-08-16
"""

import os
import sys
import time
import tempfile
import unittest
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ€§èƒ½ä¼˜åŒ–ç»„ä»¶
from core.high_performance_file_reader import (
    HighPerformanceFileReader, ReadStrategy, FileType, FileInfo, ReadMetrics
)
from core.render_performance_optimizer import (
    RenderPerformanceOptimizer, RenderStrategy, RenderMode, RenderMetrics, RenderChunk
)
from core.memory_optimization_manager import (
    MemoryOptimizationManager, MemoryStrategy, MemoryThreshold, MemoryInfo, MemoryMetrics
)
from core.performance_benchmark import (
    PerformanceBenchmark, BenchmarkType, BenchmarkResultEnum, BenchmarkResult, BenchmarkMetrics
)


class TestHighPerformanceFileReader(unittest.TestCase):
    """æµ‹è¯•é«˜æ€§èƒ½æ–‡ä»¶è¯»å–å™¨"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.temp_dir = tempfile.mkdtemp()
        self.test_file = Path(self.temp_dir) / "test.md"
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_content = "# æµ‹è¯•æ–‡ä»¶\n\nè¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•çš„Markdownæ–‡ä»¶ã€‚\n" * 100
        with open(self.test_file, 'w', encoding='utf-8') as f:
            f.write(test_content)
        
        self.file_reader = HighPerformanceFileReader()
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        self.file_reader.shutdown()
        import shutil
        shutil.rmtree(self.temp_dir)
    
    def test_file_reader_initialization(self):
        """æµ‹è¯•æ–‡ä»¶è¯»å–å™¨åˆå§‹åŒ–"""
        self.assertIsNotNone(self.file_reader)
        self.assertIsNotNone(self.file_reader.cache_manager)
        self.assertIsNotNone(self.file_reader.error_handler)
    
    def test_read_file_sync(self):
        """æµ‹è¯•åŒæ­¥æ–‡ä»¶è¯»å–"""
        result = self.file_reader.read_file(str(self.test_file), ReadStrategy.SYNC)
        
        self.assertTrue(result['success'])
        self.assertIn('content', result)
        self.assertIn('metrics', result)
        self.assertIn('file_info', result)
        
        # éªŒè¯æ–‡ä»¶ä¿¡æ¯
        file_info = result['file_info']
        self.assertEqual(file_info['file_type'], 'markdown')
        self.assertGreater(file_info['size'], 0)
    
    def test_read_file_mapped(self):
        """æµ‹è¯•å†…å­˜æ˜ å°„æ–‡ä»¶è¯»å–"""
        result = self.file_reader.read_file(str(self.test_file), ReadStrategy.MAPPED)
        
        self.assertTrue(result['success'])
        self.assertIn('content', result)
        self.assertIn('metrics', result)
    
    def test_read_file_streaming(self):
        """æµ‹è¯•æµå¼æ–‡ä»¶è¯»å–"""
        result = self.file_reader.read_file(str(self.test_file), ReadStrategy.STREAMING)
        
        self.assertTrue(result['success'])
        self.assertIn('content', result)
        self.assertIn('metrics', result)
    
    def test_file_info_cache(self):
        """æµ‹è¯•æ–‡ä»¶ä¿¡æ¯ç¼“å­˜"""
        # ç¬¬ä¸€æ¬¡è¯»å–
        info1 = self.file_reader.get_file_info(str(self.test_file))
        self.assertIsNotNone(info1)
        
        # ç¬¬äºŒæ¬¡è¯»å–åº”è¯¥ä»ç¼“å­˜è·å–
        info2 = self.file_reader.get_file_info(str(self.test_file))
        self.assertEqual(info1.path, info2.path)
    
    def test_read_stats(self):
        """æµ‹è¯•è¯»å–ç»Ÿè®¡ä¿¡æ¯"""
        # æ‰§è¡Œå‡ æ¬¡è¯»å–
        for _ in range(3):
            self.file_reader.read_file(str(self.test_file))
        
        stats = self.file_reader.get_read_stats()
        self.assertGreater(stats['total_reads'], 0)
        self.assertIn('cache_hit_rate', stats)
        self.assertIn('strategy_usage', stats)


class TestRenderPerformanceOptimizer(unittest.TestCase):
    """æµ‹è¯•æ¸²æŸ“æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.renderer = RenderPerformanceOptimizer()
        self.test_content = "# æµ‹è¯•å†…å®¹\n\nè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•Markdownå†…å®¹ã€‚\n" * 50
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        self.renderer.shutdown()
    
    def test_renderer_initialization(self):
        """æµ‹è¯•æ¸²æŸ“å™¨åˆå§‹åŒ–"""
        self.assertIsNotNone(self.renderer)
        self.assertIsNotNone(self.renderer.cache_manager)
        self.assertIsNotNone(self.renderer.error_handler)
    
    def test_render_content_single_thread(self):
        """æµ‹è¯•å•çº¿ç¨‹æ¸²æŸ“"""
        result = self.renderer.render_content(
            self.test_content, 
            RenderStrategy.SINGLE_THREAD, 
            RenderMode.FULL
        )
        
        self.assertTrue(result['success'])
        self.assertIn('html', result)
        self.assertIn('metrics', result)
        self.assertIn('content_hash', result)
    
    def test_render_content_multi_thread(self):
        """æµ‹è¯•å¤šçº¿ç¨‹æ¸²æŸ“"""
        result = self.renderer.render_content(
            self.test_content, 
            RenderStrategy.MULTI_THREAD, 
            RenderMode.FULL
        )
        
        self.assertTrue(result['success'])
        self.assertIn('html', result)
        self.assertIn('metrics', result)
    
    def test_render_content_incremental(self):
        """æµ‹è¯•å¢é‡æ¸²æŸ“"""
        result = self.renderer.render_content(
            self.test_content, 
            RenderStrategy.INCREMENTAL, 
            RenderMode.FULL
        )
        
        self.assertTrue(result['success'])
        self.assertIn('html', result)
        self.assertIn('metrics', result)
    
    def test_render_content_lazy(self):
        """æµ‹è¯•æ‡’åŠ è½½æ¸²æŸ“"""
        result = self.renderer.render_content(
            self.test_content, 
            RenderStrategy.LAZY, 
            RenderMode.SKELETON
        )
        
        self.assertTrue(result['success'])
        self.assertIn('html', result)
        self.assertIn('metrics', result)
    
    def test_render_file(self):
        """æµ‹è¯•æ–‡ä»¶æ¸²æŸ“"""
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write(self.test_content)
            temp_file = f.name
        
        try:
            result = self.renderer.render_file(temp_file)
            self.assertTrue(result['success'])
            self.assertIn('html', result)
        finally:
            os.unlink(temp_file)
    
    def test_render_stats(self):
        """æµ‹è¯•æ¸²æŸ“ç»Ÿè®¡ä¿¡æ¯"""
        # æ‰§è¡Œå‡ æ¬¡æ¸²æŸ“
        for _ in range(3):
            self.renderer.render_content(self.test_content)
        
        stats = self.renderer.get_render_stats()
        self.assertGreater(stats['total_renders'], 0)
        self.assertIn('cache_hit_rate', stats)
        self.assertIn('strategy_usage', stats)


class TestMemoryOptimizationManager(unittest.TestCase):
    """æµ‹è¯•å†…å­˜ä¼˜åŒ–ç®¡ç†å™¨"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.memory_manager = MemoryOptimizationManager()
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        self.memory_manager.shutdown()
    
    def test_memory_manager_initialization(self):
        """æµ‹è¯•å†…å­˜ç®¡ç†å™¨åˆå§‹åŒ–"""
        self.assertIsNotNone(self.memory_manager)
        self.assertIsNotNone(self.memory_manager.cache_manager)
        self.assertIsNotNone(self.memory_manager.error_handler)
    
    def test_get_memory_info(self):
        """æµ‹è¯•è·å–å†…å­˜ä¿¡æ¯"""
        memory_info = self.memory_manager.get_memory_info()
        
        self.assertIsNotNone(memory_info)
        self.assertGreater(memory_info.total_memory_mb, 0)
        self.assertGreaterEqual(memory_info.memory_percent, 0)
        self.assertLessEqual(memory_info.memory_percent, 1)
    
    def test_memory_strategy_management(self):
        """æµ‹è¯•å†…å­˜ç­–ç•¥ç®¡ç†"""
        # æµ‹è¯•è®¾ç½®ç­–ç•¥
        self.memory_manager.set_memory_strategy(MemoryStrategy.AGGRESSIVE)
        self.assertEqual(self.memory_manager.strategy, MemoryStrategy.AGGRESSIVE)
        
        self.memory_manager.set_memory_strategy(MemoryStrategy.CONSERVATIVE)
        self.assertEqual(self.memory_manager.strategy, MemoryStrategy.CONSERVATIVE)
    
    def test_memory_threshold_management(self):
        """æµ‹è¯•å†…å­˜é˜ˆå€¼ç®¡ç†"""
        # æµ‹è¯•è®¾ç½®é˜ˆå€¼
        self.memory_manager.set_memory_threshold(MemoryThreshold.HIGH, 0.8)
        self.assertEqual(self.memory_manager.memory_thresholds[MemoryThreshold.HIGH], 0.8)
    
    def test_manual_memory_optimization(self):
        """æµ‹è¯•æ‰‹åŠ¨å†…å­˜ä¼˜åŒ–"""
        result = self.memory_manager.optimize_memory()
        self.assertIsNotNone(result)
    
    def test_memory_stats(self):
        """æµ‹è¯•å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.memory_manager.get_memory_stats()
        
        self.assertIn('strategy', stats)
        self.assertIn('monitoring_interval', stats)
        self.assertIn('gc_collections', stats)
        self.assertIn('memory_thresholds', stats)


class TestPerformanceBenchmark(unittest.TestCase):
    """æµ‹è¯•æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.benchmark = PerformanceBenchmark()
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        self.benchmark.shutdown()
    
    def test_benchmark_initialization(self):
        """æµ‹è¯•åŸºå‡†æµ‹è¯•å™¨åˆå§‹åŒ–"""
        self.assertIsNotNone(self.benchmark)
        self.assertIsNotNone(self.benchmark.file_reader)
        self.assertIsNotNone(self.benchmark.render_optimizer)
        self.assertIsNotNone(self.benchmark.memory_manager)
    
    def test_create_test_files(self):
        """æµ‹è¯•åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
        test_dir = Path(tempfile.mkdtemp())
        try:
            test_files = self.benchmark.create_test_files(test_dir)
            self.assertEqual(len(test_files), 3)  # small, medium, large
            
            for test_file in test_files:
                self.assertTrue(test_file.exists())
                self.assertGreater(test_file.stat().st_size, 0)
        finally:
            import shutil
            shutil.rmtree(test_dir)
    
    def test_file_read_benchmark(self):
        """æµ‹è¯•æ–‡ä»¶è¯»å–åŸºå‡†æµ‹è¯•"""
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_dir = Path(tempfile.mkdtemp())
        try:
            test_files = self.benchmark.create_test_files(test_dir)
            
            # è¿è¡Œæ–‡ä»¶è¯»å–åŸºå‡†æµ‹è¯•
            results = self.benchmark.benchmark_file_read(test_files)
            
            self.assertGreater(len(results), 0)
            
            for result in results:
                self.assertIsNotNone(result.metrics)
                self.assertIsNotNone(result.baseline_comparison)
                self.assertIsNotNone(result.recommendations)
        finally:
            import shutil
            shutil.rmtree(test_dir)
    
    def test_render_benchmark(self):
        """æµ‹è¯•æ¸²æŸ“åŸºå‡†æµ‹è¯•"""
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_dir = Path(tempfile.mkdtemp())
        try:
            test_files = self.benchmark.create_test_files(test_dir)
            
            # è¿è¡Œæ¸²æŸ“åŸºå‡†æµ‹è¯•
            results = self.benchmark.benchmark_render(test_files)
            
            self.assertGreater(len(results), 0)
            
            for result in results:
                self.assertIsNotNone(result.metrics)
                self.assertIsNotNone(result.baseline_comparison)
                self.assertIsNotNone(result.recommendations)
        finally:
            import shutil
            shutil.rmtree(test_dir)
    
    def test_memory_benchmark(self):
        """æµ‹è¯•å†…å­˜åŸºå‡†æµ‹è¯•"""
        results = self.benchmark.benchmark_memory()
        
        self.assertGreater(len(results), 0)
        
        for result in results:
            self.assertIsNotNone(result.metrics)
            self.assertIsNotNone(result.baseline_comparison)
            self.assertIsNotNone(result.recommendations)
    
    def test_integration_benchmark(self):
        """æµ‹è¯•é›†æˆåŸºå‡†æµ‹è¯•"""
        results = self.benchmark.benchmark_integration()
        
        self.assertGreater(len(results), 0)
        
        for result in results:
            self.assertIsNotNone(result.metrics)
            self.assertIsNotNone(result.baseline_comparison)
            self.assertIsNotNone(result.recommendations)
    
    def test_generate_report(self):
        """æµ‹è¯•ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        # è¿è¡Œä¸€äº›åŸºå‡†æµ‹è¯•
        test_dir = Path(tempfile.mkdtemp())
        try:
            test_files = self.benchmark.create_test_files(test_dir)
            
            results = {
                BenchmarkType.FILE_READ.value: self.benchmark.benchmark_file_read(test_files),
                BenchmarkType.RENDER.value: self.benchmark.benchmark_render(test_files),
                BenchmarkType.MEMORY.value: self.benchmark.benchmark_memory(),
                BenchmarkType.INTEGRATION.value: self.benchmark.benchmark_integration()
            }
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.benchmark.generate_report(results)
            
            self.assertIsInstance(report, str)
            self.assertIn("æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š", report)
            self.assertIn("æµ‹è¯•æ€»ç»“", report)
        finally:
            import shutil
            shutil.rmtree(test_dir)


class TestPerformanceOptimizationIntegration(unittest.TestCase):
    """æµ‹è¯•æ€§èƒ½ä¼˜åŒ–é›†æˆ"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        _t_all = time.perf_counter()
        _t0 = time.perf_counter(); self.file_reader = HighPerformanceFileReader(); print(f"[BASE] setup.file_reader: {time.perf_counter() - _t0:.3f}s")
        _t1 = time.perf_counter(); self.renderer = RenderPerformanceOptimizer(); print(f"[BASE] setup.renderer: {time.perf_counter() - _t1:.3f}s")
        _t2 = time.perf_counter(); self.memory_manager = MemoryOptimizationManager(); print(f"[BASE] setup.memory_manager: {time.perf_counter() - _t2:.3f}s")
        _t3 = time.perf_counter(); self.benchmark = PerformanceBenchmark(); print(f"[BASE] setup.benchmark: {time.perf_counter() - _t3:.3f}s")
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        self.temp_dir = tempfile.mkdtemp()
        self.test_file = Path(self.temp_dir) / "integration_test.md"
        
        test_content = "# é›†æˆæµ‹è¯•\n\nè¿™æ˜¯ä¸€ä¸ªç”¨äºé›†æˆæµ‹è¯•çš„Markdownæ–‡ä»¶ã€‚\n" * 200
        _t4 = time.perf_counter()
        with open(self.test_file, 'w', encoding='utf-8') as f:
            f.write(test_content)
        print(f"[BASE] setup.file_io: {time.perf_counter() - _t4:.3f}s")
        print(f"[BASE] setup.total: {time.perf_counter() - _t_all:.3f}s")
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        _t_all = time.perf_counter()
        _t0 = time.perf_counter(); self.file_reader.shutdown(); print(f"[BASE] teardown.file_reader.shutdown: {time.perf_counter() - _t0:.3f}s")
        _t1 = time.perf_counter(); self.renderer.shutdown(); print(f"[BASE] teardown.renderer.shutdown: {time.perf_counter() - _t1:.3f}s")
        _t2 = time.perf_counter(); self.memory_manager.shutdown(); print(f"[BASE] teardown.memory_manager.shutdown: {time.perf_counter() - _t2:.3f}s")
        _t3 = time.perf_counter(); self.benchmark.shutdown(); print(f"[BASE] teardown.benchmark.shutdown: {time.perf_counter() - _t3:.3f}s")
        
        import shutil
        _t4 = time.perf_counter(); shutil.rmtree(self.temp_dir); print(f"[BASE] teardown.cleanup: {time.perf_counter() - _t4:.3f}s")
        print(f"[BASE] teardown.total: {time.perf_counter() - _t_all:.3f}s")
    
    def test_end_to_end_performance_workflow(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯æ€§èƒ½å·¥ä½œæµ"""
        _t_all = time.perf_counter()
        _t0 = time.perf_counter()
        read_result = self.file_reader.read_file(str(self.test_file), ReadStrategy.MAPPED)
        print(f"[PROF] e2e.read: {time.perf_counter() - _t0:.3f}s")
        self.assertTrue(read_result['success'])
        
        _t1 = time.perf_counter()
        render_result = self.renderer.render_content(
            read_result['content'], 
            RenderStrategy.MULTI_THREAD, 
            RenderMode.FULL
        )
        print(f"[PROF] e2e.render: {time.perf_counter() - _t1:.3f}s")
        self.assertTrue(render_result['success'])
        
        _t2 = time.perf_counter()
        memory_info = self.memory_manager.optimize_memory()
        print(f"[PROF] e2e.optimize_memory: {time.perf_counter() - _t2:.3f}s")
        self.assertIsNotNone(memory_info)
        
        _t3 = time.perf_counter()
        benchmark_results = self.benchmark.benchmark_file_read([self.test_file])
        print(f"[PROF] e2e.benchmark_file_read: {time.perf_counter() - _t3:.3f}s")
        self.assertGreater(len(benchmark_results), 0)
        print(f"[PROF] e2e.total: {time.perf_counter() - _t_all:.3f}s")
        
        # éªŒè¯æ•´ä¸ªæµç¨‹çš„æ€§èƒ½æŒ‡æ ‡
        read_metrics = read_result['metrics']
        render_metrics = render_result['metrics']
        
        self.assertGreater(read_metrics['throughput_mbps'], 0)
        self.assertGreater(render_metrics['render_speed_chars_per_ms'], 0)
    
    def test_performance_monitoring(self):
        """æµ‹è¯•æ€§èƒ½ç›‘æ§"""
        _t_all = time.perf_counter()
        _t_loop = time.perf_counter()
        for _ in range(5):
            self.file_reader.read_file(str(self.test_file))
            self.renderer.render_content("# æµ‹è¯•å†…å®¹\n", RenderStrategy.SINGLE_THREAD)
        print(f"[PROF] mon.loop: {time.perf_counter() - _t_loop:.3f}s")
        
        _t0 = time.perf_counter(); read_stats = self.file_reader.get_read_stats(); print(f"[PROF] mon.get_read_stats: {time.perf_counter() - _t0:.3f}s")
        _t1 = time.perf_counter(); render_stats = self.renderer.get_render_stats(); print(f"[PROF] mon.get_render_stats: {time.perf_counter() - _t1:.3f}s")
        _t2 = time.perf_counter(); memory_stats = self.memory_manager.get_memory_stats(); print(f"[PROF] mon.get_memory_stats: {time.perf_counter() - _t2:.3f}s")
        print(f"[PROF] mon.total: {time.perf_counter() - _t_all:.3f}s")
        
        # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
        self.assertGreater(read_stats['total_reads'], 0)
        self.assertGreater(render_stats['total_renders'], 0)
        self.assertIn('strategy', memory_stats)


def run_performance_tests():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹è¿è¡Œç¬¬ä¸‰é˜¶æ®µæ€§èƒ½ä¼˜åŒ–æµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestHighPerformanceFileReader,
        TestRenderPerformanceOptimizer,
        TestMemoryOptimizationManager,
        TestPerformanceBenchmark,
        TestPerformanceOptimizationIntegration
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"- è¿è¡Œæµ‹è¯•: {result.testsRun}")
    print(f"- å¤±è´¥: {len(result.failures)}")
    print(f"- é”™è¯¯: {len(result.errors)}")
    
    if result.failures:
        print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"- {test}: {traceback}")
    
    if result.errors:
        print(f"\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"- {test}: {traceback}")
    
    if result.wasSuccessful():
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¬¬ä¸‰é˜¶æ®µæ€§èƒ½ä¼˜åŒ–å®æ–½æˆåŠŸï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ä»£ç ã€‚")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_performance_tests()
    sys.exit(0 if success else 1) 