"""
å®é™…è¿è¡ŒéªŒè¯è„šæœ¬ - æ–¹æ¡ˆ4.3.3ç³»ç»Ÿé›†æˆä¸ç›‘æ§å®æ–½
éªŒè¯æ‰€æœ‰æ¨¡å—çš„å®é™…è¿è¡Œæƒ…å†µ
"""

import asyncio
import time
import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•ä¸é¡¹ç›®å†…ç¨³å®šåŒ…ç›®å½•åˆ° Python è·¯å¾„
_CUR_DIR = Path(__file__).resolve().parent
# ç›®å½•å±‚çº§ï¼š.../local_markdown_viewer/ç¬¬äºŒé˜¶æ®µå®ç°æç¤ºè¯/.../outputs
# local_markdown_viewer ä½äº parents[2]
_LMV_DIR = _CUR_DIR.parents[2]
sys.path.insert(0, str(_LMV_DIR))

# å¯¼å…¥æ‰€æœ‰å®æ–½æ¨¡å—ï¼ˆæŒ‡å‘ç¨³å®šç›®å½•ï¼‰
from integration.system_integration_coordinator import SystemIntegrationCoordinator
from monitoring.monitoring_system_deployer import MonitoringSystemDeployer
from benchmarks.performance_benchmark_tester import PerformanceBenchmarkTester
from integration.link_processor_integration_preparer import LinkProcessorIntegrationPreparer
from comparison_analysis_tool import ComparisonAnalysisTool
from integration_test_suite import IntegrationTestSuite


class ValidationTestRunner:
    """éªŒè¯æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.test_results = {}
        self.start_time = time.time()
    
    async def run_all_validation_tests(self):
        """è¿è¡Œæ‰€æœ‰éªŒè¯æµ‹è¯•"""
        print("=" * 60)
        print("æ–¹æ¡ˆ4.3.3ç³»ç»Ÿé›†æˆä¸ç›‘æ§å®æ–½ - å®é™…è¿è¡ŒéªŒè¯")
        print("=" * 60)
        
        try:
            # 1. éªŒè¯ç³»ç»Ÿé›†æˆåè°ƒå™¨
            await self._test_system_integration_coordinator()
            
            # 2. éªŒè¯ç›‘æ§ç³»ç»Ÿéƒ¨ç½²å™¨
            await self._test_monitoring_system_deployer()
            
            # 3. éªŒè¯æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨
            await self._test_performance_benchmark_tester()
            
            # 4. éªŒè¯LinkProcessoré›†æˆå‡†å¤‡å™¨
            await self._test_link_processor_integration_preparer()
            
            # 5. éªŒè¯å¯¹æ¯”åˆ†æå·¥å…·
            await self._test_comparison_analysis_tool()
            
            # 6. éªŒè¯é›†æˆæµ‹è¯•å¥—ä»¶
            await self._test_integration_test_suite()
            
            # 7. ç”ŸæˆéªŒè¯æŠ¥å‘Š
            await self._generate_validation_report()
            
        except Exception as e:
            print(f"âŒ éªŒè¯æµ‹è¯•å¤±è´¥: {e}")
            raise
    
    async def _test_system_integration_coordinator(self):
        """éªŒè¯ç³»ç»Ÿé›†æˆåè°ƒå™¨"""
        print("\nğŸ”§ éªŒè¯ç³»ç»Ÿé›†æˆåè°ƒå™¨...")
        
        try:
            coordinator = SystemIntegrationCoordinator()
            
            # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
            result = await coordinator.integrate_all_modules()
            
            # éªŒè¯ç»“æœ
            assert result["status"] == "completed", "é›†æˆçŠ¶æ€åº”ä¸ºcompleted"
            assert "total_modules" in result, "åº”åŒ…å«total_moduleså­—æ®µ"
            assert "successful_modules" in result, "åº”åŒ…å«successful_moduleså­—æ®µ"
            
            self.test_results["system_integration_coordinator"] = {
                "status": "passed",
                "result": result
            }
            
            print("âœ… ç³»ç»Ÿé›†æˆåè°ƒå™¨éªŒè¯é€šè¿‡")
            
        except Exception as e:
            self.test_results["system_integration_coordinator"] = {
                "status": "failed",
                "error": str(e)
            }
            print(f"âŒ ç³»ç»Ÿé›†æˆåè°ƒå™¨éªŒè¯å¤±è´¥: {e}")
    
    async def _test_monitoring_system_deployer(self):
        """éªŒè¯ç›‘æ§ç³»ç»Ÿéƒ¨ç½²å™¨"""
        print("\nğŸ“Š éªŒè¯ç›‘æ§ç³»ç»Ÿéƒ¨ç½²å™¨...")
        
        try:
            deployer = MonitoringSystemDeployer()
            
            # æµ‹è¯•éƒ¨ç½²åŠŸèƒ½
            result = await deployer.deploy_monitoring_system()
            
            # éªŒè¯ç»“æœ
            assert result["status"] == "success", "éƒ¨ç½²çŠ¶æ€åº”ä¸ºsuccess"
            assert "monitoring_types" in result, "åº”åŒ…å«monitoring_typeså­—æ®µ"
            assert "alert_rules_count" in result, "åº”åŒ…å«alert_rules_countå­—æ®µ"
            
            self.test_results["monitoring_system_deployer"] = {
                "status": "passed",
                "result": result
            }
            
            print("âœ… ç›‘æ§ç³»ç»Ÿéƒ¨ç½²å™¨éªŒè¯é€šè¿‡")
            
        except Exception as e:
            self.test_results["monitoring_system_deployer"] = {
                "status": "failed",
                "error": str(e)
            }
            print(f"âŒ ç›‘æ§ç³»ç»Ÿéƒ¨ç½²å™¨éªŒè¯å¤±è´¥: {e}")
    
    async def _test_performance_benchmark_tester(self):
        """éªŒè¯æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""
        print("\nâš¡ éªŒè¯æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨...")
        
        try:
            tester = PerformanceBenchmarkTester()
            
            # æµ‹è¯•åŸºå‡†æµ‹è¯•åŠŸèƒ½
            result = await tester.run_comprehensive_benchmark()
            
            # éªŒè¯ç»“æœ
            assert result["status"] == "completed", "åŸºå‡†æµ‹è¯•çŠ¶æ€åº”ä¸ºcompleted"
            assert "baseline" in result, "åº”åŒ…å«baselineå­—æ®µ"
            assert "test_results" in result, "åº”åŒ…å«test_resultså­—æ®µ"
            
            self.test_results["performance_benchmark_tester"] = {
                "status": "passed",
                "result": result
            }
            
            print("âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨éªŒè¯é€šè¿‡")
            
        except Exception as e:
            self.test_results["performance_benchmark_tester"] = {
                "status": "failed",
                "error": str(e)
            }
            print(f"âŒ æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨éªŒè¯å¤±è´¥: {e}")
    
    async def _test_link_processor_integration_preparer(self):
        """éªŒè¯LinkProcessoré›†æˆå‡†å¤‡å™¨"""
        print("\nğŸ”— éªŒè¯LinkProcessoré›†æˆå‡†å¤‡å™¨...")
        
        try:
            preparer = LinkProcessorIntegrationPreparer()
            
            # æµ‹è¯•é›†æˆå‡†å¤‡åŠŸèƒ½
            result = await preparer.prepare_link_processor_integration()
            
            # éªŒè¯ç»“æœ
            assert result["status"] == "completed", "å‡†å¤‡çŠ¶æ€åº”ä¸ºcompleted"
            assert "interfaces_count" in result, "åº”åŒ…å«interfaces_countå­—æ®µ"
            assert "integration_points_count" in result, "åº”åŒ…å«integration_points_countå­—æ®µ"
            
            self.test_results["link_processor_integration_preparer"] = {
                "status": "passed",
                "result": result
            }
            
            print("âœ… LinkProcessoré›†æˆå‡†å¤‡å™¨éªŒè¯é€šè¿‡")
            
        except Exception as e:
            self.test_results["link_processor_integration_preparer"] = {
                "status": "failed",
                "error": str(e)
            }
            print(f"âŒ LinkProcessoré›†æˆå‡†å¤‡å™¨éªŒè¯å¤±è´¥: {e}")
    
    async def _test_comparison_analysis_tool(self):
        """éªŒè¯å¯¹æ¯”åˆ†æå·¥å…·"""
        print("\nğŸ“ˆ éªŒè¯å¯¹æ¯”åˆ†æå·¥å…·...")
        
        try:
            analyzer = ComparisonAnalysisTool()
            
            # æµ‹è¯•å¯¹æ¯”åˆ†æåŠŸèƒ½
            result = await analyzer.run_comprehensive_comparison_analysis()
            
            # éªŒè¯ç»“æœ
            assert result["status"] == "completed", "åˆ†æçŠ¶æ€åº”ä¸ºcompleted"
            assert "comparison_results" in result, "åº”åŒ…å«comparison_resultså­—æ®µ"
            assert "improvement_recommendations" in result, "åº”åŒ…å«improvement_recommendationså­—æ®µ"
            
            self.test_results["comparison_analysis_tool"] = {
                "status": "passed",
                "result": result
            }
            
            print("âœ… å¯¹æ¯”åˆ†æå·¥å…·éªŒè¯é€šè¿‡")
            
        except Exception as e:
            self.test_results["comparison_analysis_tool"] = {
                "status": "failed",
                "error": str(e)
            }
            print(f"âŒ å¯¹æ¯”åˆ†æå·¥å…·éªŒè¯å¤±è´¥: {e}")
    
    async def _test_integration_test_suite(self):
        """éªŒè¯é›†æˆæµ‹è¯•å¥—ä»¶"""
        print("\nğŸ§ª éªŒè¯é›†æˆæµ‹è¯•å¥—ä»¶...")
        
        try:
            test_suite = IntegrationTestSuite()
            
            # æµ‹è¯•é›†æˆæµ‹è¯•åŠŸèƒ½
            result = await test_suite.run_all_integration_tests()
            
            # éªŒè¯ç»“æœ
            assert "test_summary" in result, "åº”åŒ…å«test_summaryå­—æ®µ"
            assert "test_results" in result, "åº”åŒ…å«test_resultså­—æ®µ"
            
            self.test_results["integration_test_suite"] = {
                "status": "passed",
                "result": result
            }
            
            print("âœ… é›†æˆæµ‹è¯•å¥—ä»¶éªŒè¯é€šè¿‡")
            
        except Exception as e:
            self.test_results["integration_test_suite"] = {
                "status": "failed",
                "error": str(e)
            }
            print(f"âŒ é›†æˆæµ‹è¯•å¥—ä»¶éªŒè¯å¤±è´¥: {e}")
    
    async def _generate_validation_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("éªŒè¯æŠ¥å‘Š")
        print("=" * 60)
        
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results.values() if r["status"] == "passed"])
        failed_tests = len([r for r in self.test_results.values() if r["status"] == "failed"])
        
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"é€šè¿‡æµ‹è¯•: {passed_tests}")
        print(f"å¤±è´¥æµ‹è¯•: {failed_tests}")
        print(f"æˆåŠŸç‡: {(passed_tests / total_tests * 100):.2f}%")
        
        print(f"\næ€»æ‰§è¡Œæ—¶é—´: {time.time() - self.start_time:.2f}ç§’")
        
        # è¯¦ç»†ç»“æœ
        print("\nè¯¦ç»†ç»“æœ:")
        for test_name, result in self.test_results.items():
            status_icon = "âœ…" if result["status"] == "passed" else "âŒ"
            print(f"{status_icon} {test_name}: {result['status']}")
            if result["status"] == "failed":
                print(f"   é”™è¯¯: {result['error']}")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = Path("validation_report.json")
        import json
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, default=str, indent=2)
        
        print(f"\néªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


async def main():
    """ä¸»å‡½æ•°"""
    runner = ValidationTestRunner()
    await runner.run_all_validation_tests()


if __name__ == "__main__":
    asyncio.run(main())