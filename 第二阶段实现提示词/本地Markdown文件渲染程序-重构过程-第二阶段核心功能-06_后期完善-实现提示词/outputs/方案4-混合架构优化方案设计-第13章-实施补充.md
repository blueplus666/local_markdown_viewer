# æ–¹æ¡ˆ4-æ··åˆæ¶æ„ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡-ç¬¬13ç« -å®æ–½è¡¥å……

## 13.0 ä¼šè¯å…ƒæ•°æ®
- ä¼šè¯ID: 2025-08-15-16-24-41
- æ–‡æ¡£ç±»å‹: å®æ–½è¡¥å……ï¼ˆèšåˆè§†å›¾ï¼‰
- ç»„æˆæ¥æºï¼š
  - æ–¹æ¡ˆ4-æ··åˆæ¶æ„ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡-æŠ€æœ¯å®ç°ç»†èŠ‚ä¸æ€§èƒ½åŸºå‡†.mdï¼ˆç«‹å³è¡¥å……ï¼‰
  - æ–¹æ¡ˆ4-æ··åˆæ¶æ„ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡-éƒ¨ç½²è¿ç»´ä¸ç›‘æ§é…ç½®.mdï¼ˆçŸ­æœŸå®Œå–„ï¼‰
  - æ–¹æ¡ˆ4-æ··åˆæ¶æ„ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡-é•¿æœŸæ€§èƒ½ä¼˜åŒ–ä¸ç¨³å®šæ€§æµ‹è¯•.mdï¼ˆé•¿æœŸä¼˜åŒ–ï¼‰
  - é™„å½•-æŠ€æœ¯æ·±æŒ–ï¼šæ–¹æ¡ˆ4-æ··åˆæ¶æ„ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡-æŠ€æœ¯å®ç°ç»†èŠ‚è¡¥å…….mdï¼ˆå¼•ç”¨ç‰‡æ®µï¼Œè¶…èŒƒå›´éƒ¨åˆ†æ ‡æ³¨ä¸ºåç»­é€‰é¡¹ï¼‰

## 13.1 ç´¢å¼•ï¼ˆæœ¬ç« å†…ï¼‰
- 13.2 æŠ€æœ¯å®ç°ç»†èŠ‚ä¸æ€§èƒ½åŸºå‡†ï¼ˆç«‹å³è¡¥å……ï¼‰
- 13.3 éƒ¨ç½²è¿ç»´ä¸ç›‘æ§é…ç½®ï¼ˆçŸ­æœŸå®Œå–„ï¼‰
- 13.4 é•¿æœŸæ€§èƒ½ä¼˜åŒ–ä¸ç¨³å®šæ€§æµ‹è¯•ï¼ˆé•¿æœŸä¼˜åŒ–ï¼‰
- 13.A é™„å½•-æŠ€æœ¯æ·±æŒ–ï¼ˆå¼•ç”¨ä¸èŒƒå›´æ ‡æ³¨ï¼‰

---

## 13.2 æŠ€æœ¯å®ç°ç»†èŠ‚ä¸æ€§èƒ½åŸºå‡†ï¼ˆç«‹å³è¡¥å……ï¼‰

### 1. ä¼šè¯å…ƒæ•°æ®
- ä¼šè¯ID: 2025-08-15-16-24-41
- æ–‡æ¡£ç±»å‹: æŠ€æœ¯å®ç°ç»†èŠ‚ä¸æ€§èƒ½åŸºå‡†è¡¥å……

### 2. å¹¶å‘ä¸å¼‚æ­¥å®ç°ç»†èŠ‚

#### 2.1 æ¨¡å‹é€‰æ‹©ä¸é€‚ç”¨åœºæ™¯
- asyncio: é€‚åˆå¤§é‡å¹¶å‘ä¸” I/O å¯†é›†ï¼ˆæ–‡ä»¶/ç½‘ç»œï¼‰ï¼Œéœ€äº‹ä»¶å¾ªç¯æ‰˜ç®¡
- çº¿ç¨‹æ±  ThreadPoolExecutor: é€‚é…ç°æœ‰åŒæ­¥ä»£ç ï¼Œå¹³æ»‘æ”¹é€ é˜»å¡ I/O
- è¿›ç¨‹æ±  ProcessPoolExecutor: CPU å¯†é›†ï¼ˆé‡åº¦è§£æ/å‹ç¼©ï¼‰ï¼Œé¿å… GIL å½±å“

æœ¬é¡¹ç›®å»ºè®®ï¼šä»¥"çº¿ç¨‹æ±  + è½»é‡äº‹ä»¶å¾ªç¯"æ··åˆæ–¹æ¡ˆä¸ºä¸»ã€‚
- FileResolver è¯»æ–‡ä»¶ä¸ç¼–ç æ£€æµ‹ â†’ çº¿ç¨‹æ± 
- å¤§æ–‡ä»¶åˆ†å—æ¸²æŸ“ï¼ˆåç»­ï¼‰â†’ çº¿ç¨‹æ± /å¼‚æ­¥æµå¼
- CPU é‡ä»»åŠ¡ï¼ˆå¯é€‰ï¼‰â†’ è¿›ç¨‹æ± ï¼ˆä¿ç•™æ‰©å±•ç‚¹ï¼‰

#### 2.2 çº¿ç¨‹æ± å°è£…ï¼ˆè¯»æ–‡ä»¶ï¼‰
```python
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path

def read_text_file(path: Path, encoding: str) -> str:
	with open(path, 'r', encoding=encoding, errors='replace') as f:
		return f.read()

class FileIOExecutor:
	def __init__(self, max_workers: int = 4):
		self._pool = ThreadPoolExecutor(max_workers=max_workers)
	
	def submit_read(self, path: Path, encoding: str):
		return self._pool.submit(read_text_file, path, encoding)
```
ä½¿ç”¨æ–¹å¼ï¼ˆContentPreview / Renderer è°ƒç”¨å¤„ï¼‰ï¼š
```python
io = FileIOExecutor(max_workers=4)
future = io.submit_read(Path(file_path), encoding)
content = future.result(timeout=10)
```

#### 2.3 å¼‚æ­¥æ¥å£ï¼ˆå¯é€‰ï¼‰
```python
import asyncio
import functools

async def run_in_executor(func, *args, loop=None):
	loop = loop or asyncio.get_event_loop()
	return await loop.run_in_executor(None, functools.partial(func, *args))
```

### 3. ç»Ÿä¸€ç¼“å­˜ä¸€è‡´æ€§ä¸å¤±æ•ˆ

#### 3.1 é”®è®¾è®¡ä¸å‘½å
- æ¸²æŸ“é”®: `render:{sha256(content)[:16]}:{md5(options_json)[:8]}`
- æ–‡ä»¶é”®: `file:{abs_path}:{mtime}`
- é“¾æ¥é”®: `link:{md5(url)}` / `link_resolve:{md5(url)}:{base}`

#### 3.2 å¤±æ•ˆè§¦å‘
- æ–‡ä»¶å˜æ›´ â†’ å¤±æ•ˆ file/render/content ç›¸å…³é”®
- é…ç½®å˜æ›´ â†’ å¤±æ•ˆå¯¹åº”å‘½åç©ºé—´ï¼ˆå¦‚ markdown.*ï¼‰
- æ¨¡å—æ›´æ–° â†’ å¤±æ•ˆ import/renderer-selection ç›¸å…³é”®

#### 3.3 å¹¶å‘å®‰å…¨
- è¯»å¤šå†™å°‘ï¼Œç”¨è¯»å†™é”/ç»†ç²’åº¦é”åŒ…è£¹ set/delete
- ç»Ÿä¸€å…¥å£æ“ä½œï¼Œé¿å…ç»•è¿‡ CacheManager ç›´æ¥æ”¹å†…éƒ¨ç»“æ„

### 4. æ¸²æŸ“å™¨é€‰æ‹©ç­–ç•¥ç»†åŒ–

#### 4.1 è¯„åˆ†ç»´åº¦
- å¯ç”¨æ€§: æˆåŠŸå¯¼å…¥/æ¢æµ‹å  40%
- æ€§èƒ½å†å²: å¹³å‡æ¸²æŸ“æ—¶é—´å  40%
- ç¨³å®šæ€§: å¤±è´¥ç‡åå‘è®¡åˆ†å  20%

#### 4.2 é€‰æ‹©æµç¨‹
```python
def select_renderer(candidates):
	# candidates: [{'name': 'markdown_processor', 'available': True, 'avg_ms': 12.3, 'fail_rate': 0.02}, ...]
	if not candidates:
		return 'text_fallback'
	
	scores = []
	for c in candidates:
		if not c['available']:
			continue
		
		# å¯ç”¨æ€§å¾—åˆ† (40%)
		availability_score = 1.0
		
		# æ€§èƒ½å¾—åˆ† (40%) - æ—¶é—´è¶ŠçŸ­å¾—åˆ†è¶Šé«˜
		performance_score = max(0, 1 - (c['avg_ms'] / 100))  # 100msä¸ºåŸºå‡†
		
		# ç¨³å®šæ€§å¾—åˆ† (20%) - å¤±è´¥ç‡è¶Šä½å¾—åˆ†è¶Šé«˜
		stability_score = max(0, 1 - c['fail_rate'])
		
		total_score = (availability_score * 0.4 + 
					  performance_score * 0.4 + 
					  stability_score * 0.2)
		
		scores.append((c['name'], total_score))
	
	if not scores:
		return 'text_fallback'
	
	# è¿”å›å¾—åˆ†æœ€é«˜çš„æ¸²æŸ“å™¨
	return max(scores, key=lambda x: x[1])[0]
```

### 5. æ€§èƒ½åŸºå‡†æµ‹è¯•æ–¹æ³•ä¸éªŒæ”¶æ ‡å‡†

#### 5.1 åŸºå‡†æµ‹è¯•ç¯å¢ƒé…ç½®
```python
class PerformanceBenchmark:
    def __init__(self):
        self.test_files = {
            'small': 'test_data/small.md',      # < 10KB
            'medium': 'test_data/medium.md',    # 10-100KB
            'large': 'test_data/large.md',      # 100KB-1MB
            'huge': 'test_data/huge.md'         # > 1MB
        }
        self.iterations = 100
        self.warmup_runs = 10
        
    def setup_environment(self):
        """é…ç½®åŸºå‡†æµ‹è¯•ç¯å¢ƒ"""
        # æ¸…ç†ç¼“å­˜
        self.clear_all_caches()
        # é¢„çƒ­JVM/è§£é‡Šå™¨
        self.warmup_system()
        # è®¾ç½®CPUäº²å’Œæ€§ï¼ˆLinuxï¼‰
        self.set_cpu_affinity()
```

#### 5.2 æ€§èƒ½æŒ‡æ ‡æ”¶é›†æ–¹æ³•
```python
    def collect_metrics(self, operation_name: str, operation_func, *args):
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        metrics = {
            'operation': operation_name,
            'iterations': self.iterations,
            'times': [],
            'memory_usage': [],
            'cpu_usage': []
        }
        
        # é¢„çƒ­è¿è¡Œ
        for _ in range(self.warmup_runs):
            operation_func(*args)
        
        # æ­£å¼æµ‹è¯•
        for i in range(self.iterations):
            start_time = time.perf_counter()
            start_memory = psutil.Process().memory_info().rss
            start_cpu = psutil.Process().cpu_percent()
            
            result = operation_func(*args)
            
            end_time = time.perf_counter()
            end_memory = psutil.Process().memory_info().rss
            end_cpu = psutil.Process().cpu_percent()
            
            metrics['times'].append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
            metrics['memory_usage'].append(end_memory - start_memory)
            metrics['cpu_usage'].append(end_cpu - start_cpu)
        
        return metrics
```

#### 5.3 éªŒæ”¶æ ‡å‡†é˜ˆå€¼è®¾ç½®
```python
    def get_acceptance_thresholds(self):
        """è·å–éªŒæ”¶æ ‡å‡†é˜ˆå€¼"""
        return {
            'file_loading': {
                'small': {'max_time_ms': 50, 'max_memory_mb': 5},
                'medium': {'max_time_ms': 200, 'max_memory_mb': 15},
                'large': {'max_time_ms': 1000, 'max_memory_mb': 50},
                'huge': {'max_time_ms': 5000, 'max_memory_mb': 200}
            },
            'rendering': {
                'small': {'max_time_ms': 100, 'max_memory_mb': 10},
                'medium': {'max_time_ms': 500, 'max_memory_mb': 30},
                'large': {'max_time_ms': 2000, 'max_memory_mb': 100},
                'huge': {'max_time_ms': 10000, 'max_memory_mb': 400}
            },
            'cache_performance': {
                'hit_rate_min': 0.8,      # ç¼“å­˜å‘½ä¸­ç‡æœ€ä½80%
                'eviction_rate_max': 0.1, # ç¼“å­˜æ·˜æ±°ç‡æœ€é«˜10%
                'memory_overhead_max': 0.2 # å†…å­˜å¼€é”€æœ€é«˜20%
            }
        }
```

#### 5.4 æ€§èƒ½å›å½’æµ‹è¯•æµç¨‹
```python
    def run_regression_test(self):
        """è¿è¡Œæ€§èƒ½å›å½’æµ‹è¯•"""
        print("å¼€å§‹æ€§èƒ½å›å½’æµ‹è¯•...")
        
        # 1. æ”¶é›†å½“å‰æ€§èƒ½æŒ‡æ ‡
        current_metrics = self.collect_current_metrics()
        
        # 2. ä¸åŸºå‡†æŒ‡æ ‡æ¯”è¾ƒ
        regression_results = self.compare_with_baseline(current_metrics)
        
        # 3. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_regression_report(regression_results)
        
        # 4. æ£€æŸ¥æ˜¯å¦é€šè¿‡éªŒæ”¶æ ‡å‡†
        passed = self.check_acceptance_criteria(regression_results)
        
        if not passed:
            print("âŒ æ€§èƒ½å›å½’æµ‹è¯•æœªé€šè¿‡éªŒæ”¶æ ‡å‡†")
            return False
        
        print("âœ… æ€§èƒ½å›å½’æµ‹è¯•é€šè¿‡éªŒæ”¶æ ‡å‡†")
        return True
```

### 6. é‡è¯•ä¸é™çº§ç­–ç•¥å®ç°

#### 6.1 æ™ºèƒ½é‡è¯•æœºåˆ¶
```python
class SmartRetryMechanism:
    def __init__(self, max_retries: int = 3, base_delay: float = 1.0):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.retry_count = 0
        
    def execute_with_retry(self, operation, *args, **kwargs):
        """æ‰§è¡Œæ“ä½œï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•"""
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                return operation(*args, **kwargs)
            except Exception as e:
                last_exception = e
                if attempt < self.max_retries:
                    delay = self.calculate_delay(attempt)
                    time.sleep(delay)
                    self.retry_count += 1
                    continue
                else:
                    break
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªå¼‚å¸¸
        raise last_exception
    
    def calculate_delay(self, attempt: int) -> float:
        """è®¡ç®—é‡è¯•å»¶è¿Ÿæ—¶é—´"""
        # æŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
        delay = self.base_delay * (2 ** attempt)
        jitter = random.uniform(0, 0.1 * delay)
        return delay + jitter
```

#### 6.2 é™çº§ç­–ç•¥å®ç°
```python
class RendererFallbackStrategy:
    def __init__(self):
        self.fallback_chain = [
            'markdown_processor',
            'mistune',
            'markdown',
            'text_fallback'
        ]
    
    def render_with_fallback(self, content: str, options: dict = None):
        """ä½¿ç”¨é™çº§ç­–ç•¥æ¸²æŸ“Markdown"""
        for renderer_name in self.fallback_chain:
            try:
                renderer = self.get_renderer(renderer_name)
                if renderer:
                    result = renderer.render(content, options or {})
                    return result
            except Exception as e:
                print(f"æ¸²æŸ“å™¨ {renderer_name} å¤±è´¥: {e}")
                continue
        
        # æ‰€æœ‰æ¸²æŸ“å™¨éƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨çº¯æ–‡æœ¬é™çº§
        return self.text_fallback(content)
    
    def text_fallback(self, content: str) -> str:
        """çº¯æ–‡æœ¬é™çº§å¤„ç†"""
        # ç®€å•çš„æ–‡æœ¬åˆ°HTMLè½¬æ¢
        lines = content.split('\n')
        html_lines = []
        
        for line in lines:
            if line.strip().startswith('#'):
                # æ ‡é¢˜è¡Œ
                level = len(line) - len(line.lstrip('#'))
                text = line.strip('#').strip()
                html_lines.append(f'<h{min(level, 6)}>{text}</h{level}>')
            elif line.strip().startswith('- '):
                # åˆ—è¡¨é¡¹
                text = line.strip('- ').strip()
                html_lines.append(f'<li>{text}</li>')
            elif line.strip():
                # æ™®é€šæ®µè½
                html_lines.append(f'<p>{line.strip()}</p>')
            else:
                # ç©ºè¡Œ
                html_lines.append('<br>')
        
        return '\n'.join(html_lines)
```

### 7. æ€§èƒ½åŸºçº¿ä¸é—¨æ§›è®¾ç½®

#### 7.1 æ€§èƒ½åŸºçº¿å®šä¹‰
```python
class PerformanceBaseline:
    def __init__(self):
        self.baselines = {
            'file_loading': {
                'small': {'p50_ms': 30, 'p95_ms': 50, 'p99_ms': 80},
                'medium': {'p50_ms': 120, 'p95_ms': 200, 'p99_ms': 300},
                'large': {'p50_ms': 600, 'p95_ms': 1000, 'p99_ms': 1500},
                'huge': {'p50_ms': 3000, 'p95_ms': 5000, 'p99_ms': 8000}
            },
            'rendering': {
                'small': {'p50_ms': 60, 'p95_ms': 100, 'p99_ms': 150},
                'medium': {'p50_ms': 250, 'p95_ms': 500, 'p99_ms': 800},
                'large': {'p50_ms': 1200, 'p95_ms': 2000, 'p99_ms': 3000},
                'huge': {'p50_ms': 6000, 'p95_ms': 10000, 'p99_ms': 15000}
            }
        }
    
    def is_performance_acceptable(self, metrics: dict, file_size: str) -> bool:
        """æ£€æŸ¥æ€§èƒ½æ˜¯å¦å¯æ¥å—"""
        if file_size not in self.baselines['file_loading']:
            return False
        
        baseline = self.baselines['file_loading'][file_size]
        
        # æ£€æŸ¥P95æ€§èƒ½æ˜¯å¦åœ¨åŸºçº¿èŒƒå›´å†…
        p95_time = np.percentile(metrics['times'], 95)
        return p95_time <= baseline['p95_ms']
```

#### 7.2 æ€§èƒ½é—¨æ§›æ£€æŸ¥
```python
    def check_performance_thresholds(self, metrics: dict) -> dict:
        """æ£€æŸ¥æ€§èƒ½é—¨æ§›"""
        results = {
            'passed': True,
            'warnings': [],
            'failures': []
        }
        
        # æ£€æŸ¥å“åº”æ—¶é—´é—¨æ§›
        p95_time = np.percentile(metrics['times'], 95)
        if p95_time > 1000:  # 1ç§’é—¨æ§›
            results['failures'].append(f"P95å“åº”æ—¶é—´ {p95_time:.2f}ms è¶…è¿‡1ç§’é—¨æ§›")
            results['passed'] = False
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨é—¨æ§›
        avg_memory = np.mean(metrics['memory_usage'])
        if avg_memory > 100 * 1024 * 1024:  # 100MBé—¨æ§›
            results['warnings'].append(f"å¹³å‡å†…å­˜ä½¿ç”¨ {avg_memory/1024/1024:.2f}MB æ¥è¿‘100MBé—¨æ§›")
        
        # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡é—¨æ§›
        if 'cache_hit_rate' in metrics:
            hit_rate = metrics['cache_hit_rate']
            if hit_rate < 0.8:  # 80%é—¨æ§›
                results['warnings'].append(f"ç¼“å­˜å‘½ä¸­ç‡ {hit_rate:.2%} ä½äº80%é—¨æ§›")
        
        return results
```

---

## 13.3 éƒ¨ç½²è¿ç»´ä¸ç›‘æ§é…ç½®ï¼ˆçŸ­æœŸå®Œå–„ï¼‰

### 1. ä¼šè¯å…ƒæ•°æ®
- ä¼šè¯ID: 2025-08-15-16-24-41
- æ–‡æ¡£ç±»å‹: éƒ¨ç½²è¿ç»´ä¸ç›‘æ§é…ç½®è¡¥å……

### 2. éƒ¨ç½²ç­–ç•¥

#### 2.1 ç¯å¢ƒåˆ†ç¦»
```python
class EnvironmentManager:
    def __init__(self):
        self.environments = {
            'development': {
                'cache_size': 100,
                'log_level': 'DEBUG',
                'monitoring': False,
                'feature_flags': {
                    'markdown.use_dynamic_import': True,
                    'markdown.fallback_enabled': True,
                    'content_viewer.cache_limit': 50
                }
            },
            'staging': {
                'cache_size': 500,
                'log_level': 'INFO',
                'monitoring': True,
                'feature_flags': {
                    'markdown.use_dynamic_import': True,
                    'markdown.fallback_enabled': True,
                    'content_viewer.cache_limit': 200
                }
            },
            'production': {
                'cache_size': 2000,
                'log_level': 'WARNING',
                'monitoring': True,
                'feature_flags': {
                    'markdown.use_dynamic_import': False,  # ç”Ÿäº§ç¯å¢ƒç¦ç”¨åŠ¨æ€å¯¼å…¥
                    'markdown.fallback_enabled': True,
                    'content_viewer.cache_limit': 1000
                }
            }
        }
    
    def get_config(self, env: str) -> dict:
        """è·å–æŒ‡å®šç¯å¢ƒçš„é…ç½®"""
        if env not in self.environments:
            raise ValueError(f"æœªçŸ¥ç¯å¢ƒ: {env}")
        return self.environments[env].copy()
```

#### 2.2 Feature Flags ç®¡ç†
```python
class FeatureFlagManager:
    def __init__(self, config: dict):
        self.flags = config.get('feature_flags', {})
        self.flag_history = []
    
    def is_enabled(self, flag_name: str) -> bool:
        """æ£€æŸ¥åŠŸèƒ½å¼€å…³æ˜¯å¦å¯ç”¨"""
        return self.flags.get(flag_name, False)
    
    def set_flag(self, flag_name: str, enabled: bool):
        """è®¾ç½®åŠŸèƒ½å¼€å…³çŠ¶æ€"""
        old_value = self.flags.get(flag_name, False)
        self.flags[flag_name] = enabled
        
        # è®°å½•å˜æ›´å†å²
        self.flag_history.append({
            'flag': flag_name,
            'old_value': old_value,
            'new_value': enabled,
            'timestamp': time.time()
        })
        
        # å¦‚æœå¯ç”¨äº†æ–°åŠŸèƒ½ï¼Œæ¸…ç†ç›¸å…³ç¼“å­˜
        if enabled and flag_name.startswith('markdown.'):
            self.clear_markdown_cache()
    
    def get_flag_status(self) -> dict:
        """è·å–æ‰€æœ‰åŠŸèƒ½å¼€å…³çŠ¶æ€"""
        return self.flags.copy()
```

### 3. é…ç½®è¿ç§»å·¥å…·

#### 3.1 é…ç½®è¿ç§»è„šæœ¬
```python
class ConfigMigrationTool:
    def __init__(self, source_config_path: str, target_config_path: str):
        self.source_path = Path(source_config_path)
        self.target_path = Path(target_config_path)
        self.migration_log = []
        
    def migrate_config(self) -> bool:
        """æ‰§è¡Œé…ç½®è¿ç§»"""
        try:
            print(f"å¼€å§‹é…ç½®è¿ç§»: {self.source_path} -> {self.target_path}")
            
            # 1. å¤‡ä»½åŸé…ç½®
            self.backup_source_config()
            
            # 2. è¯»å–æºé…ç½®
            source_config = self.load_source_config()
            
            # 3. è½¬æ¢é…ç½®æ ¼å¼
            target_config = self.transform_config(source_config)
            
            # 4. éªŒè¯æ–°é…ç½®
            if not self.validate_config(target_config):
                raise ValueError("æ–°é…ç½®éªŒè¯å¤±è´¥")
            
            # 5. å†™å…¥ç›®æ ‡é…ç½®
            self.write_target_config(target_config)
            
            # 6. è®°å½•è¿ç§»æ—¥å¿—
            self.record_migration_success()
            
            print("âœ… é…ç½®è¿ç§»æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ é…ç½®è¿ç§»å¤±è´¥: {e}")
            self.record_migration_failure(str(e))
            return False
    
    def backup_source_config(self):
        """å¤‡ä»½æºé…ç½®æ–‡ä»¶"""
        backup_path = self.source_path.with_suffix('.backup')
        shutil.copy2(self.source_path, backup_path)
        print(f"æºé…ç½®å·²å¤‡ä»½åˆ°: {backup_path}")
    
    def transform_config(self, source_config: dict) -> dict:
        """è½¬æ¢é…ç½®æ ¼å¼"""
        target_config = {
            'version': '2.0.0',
            'migration_date': time.strftime('%Y-%m-%d %H:%M:%S'),
            'original_config': source_config
        }
        
        # è½¬æ¢æ—§é…ç½®åˆ°æ–°æ ¼å¼
        if 'markdown' in source_config:
            target_config['markdown'] = {
                'use_dynamic_import': source_config['markdown'].get('dynamic_import', False),
                'fallback_enabled': source_config['markdown'].get('fallback', True),
                'cache_size': source_config['markdown'].get('cache_size', 100)
            }
        
        if 'cache' in source_config:
            target_config['cache'] = {
                'unified_manager': True,
                'namespaces': ['render', 'content', 'import', 'file_info', 'encoding'],
                'max_size': source_config['cache'].get('max_size', 1000),
                'ttl': source_config['cache'].get('ttl', 3600)
            }
        
        return target_config
```

#### 3.2 è¿ç§»éªŒè¯å·¥å…·
```python
class MigrationValidator:
    def __init__(self):
        self.validation_rules = {
            'required_fields': ['version', 'migration_date'],
            'field_types': {
                'version': str,
                'migration_date': str,
                'markdown': dict,
                'cache': dict
            },
            'value_constraints': {
                'cache.max_size': lambda x: isinstance(x, int) and 100 <= x <= 10000,
                'cache.ttl': lambda x: isinstance(x, int) and 60 <= x <= 86400
            }
        }
    
    def validate_config(self, config: dict) -> dict:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        results = {
            'valid': True,
            'errors': [],
            'warnings': []
        }
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        for field in self.validation_rules['required_fields']:
            if field not in config:
                results['errors'].append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                results['valid'] = False
        
        # æ£€æŸ¥å­—æ®µç±»å‹
        for field, expected_type in self.validation_rules['field_types'].items():
            if field in config and not isinstance(config[field], expected_type):
                results['errors'].append(f"å­—æ®µ {field} ç±»å‹é”™è¯¯ï¼ŒæœŸæœ› {expected_type.__name__}")
                results['valid'] = False
        
        # æ£€æŸ¥å€¼çº¦æŸ
        for field_path, constraint_func in self.validation_rules['value_constraints'].items():
            value = self.get_nested_value(config, field_path)
            if value is not None and not constraint_func(value):
                results['warnings'].append(f"å­—æ®µ {field_path} å€¼å¯èƒ½è¶…å‡ºå»ºè®®èŒƒå›´")
        
        return results
    
    def get_nested_value(self, config: dict, field_path: str):
        """è·å–åµŒå¥—å­—æ®µå€¼"""
        keys = field_path.split('.')
        value = config
        try:
            for key in keys:
                value = value[key]
            return value
        except (KeyError, TypeError):
            return None
```

#### 3.3 å›æ»šé…ç½®å¤‡ä»½
```python
class ConfigBackupManager:
    def __init__(self, config_dir: str):
        self.config_dir = Path(config_dir)
        self.backup_dir = self.config_dir / 'backups'
        self.backup_dir.mkdir(exist_ok=True)
        
    def create_backup(self, config_name: str) -> str:
        """åˆ›å»ºé…ç½®å¤‡ä»½"""
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        backup_name = f"{config_name}_{timestamp}.backup"
        backup_path = self.backup_dir / backup_name
        
        source_path = self.config_dir / f"{config_name}.json"
        if source_path.exists():
            shutil.copy2(source_path, backup_path)
            print(f"é…ç½®å¤‡ä»½å·²åˆ›å»º: {backup_path}")
            return str(backup_path)
        else:
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
    
    def restore_backup(self, backup_path: str, config_name: str):
        """ä»å¤‡ä»½æ¢å¤é…ç½®"""
        backup_file = Path(backup_path)
        if not backup_file.exists():
            raise FileNotFoundError(f"å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_path}")
        
        target_path = self.config_dir / f"{config_name}.json"
        shutil.copy2(backup_file, target_path)
        print(f"é…ç½®å·²ä»å¤‡ä»½æ¢å¤: {backup_path} -> {target_path}")
    
    def list_backups(self, config_name: str) -> list:
        """åˆ—å‡ºæŒ‡å®šé…ç½®çš„å¤‡ä»½"""
        backups = []
        for backup_file in self.backup_dir.glob(f"{config_name}_*.backup"):
            stat = backup_file.stat()
            backups.append({
                'file': backup_file.name,
                'size': stat.st_size,
                'created': time.ctime(stat.st_ctime),
                'path': str(backup_file)
            })
        
        return sorted(backups, key=lambda x: x['created'], reverse=True)
```

#### 3.4 è¿ç§»è¿›åº¦ç›‘æ§
```python
class MigrationProgressMonitor:
    def __init__(self):
        self.progress = 0
        self.steps = []
        self.current_step = None
        self.start_time = None
        
    def start_migration(self, total_steps: int):
        """å¼€å§‹è¿ç§»"""
        self.progress = 0
        self.steps = [{'name': f'æ­¥éª¤{i+1}', 'status': 'pending'} for i in range(total_steps)]
        self.start_time = time.time()
        print(f"å¼€å§‹è¿ç§»ï¼Œå…± {total_steps} ä¸ªæ­¥éª¤")
    
    def update_progress(self, step_index: int, status: str, message: str = ""):
        """æ›´æ–°è¿ç§»è¿›åº¦"""
        if 0 <= step_index < len(self.steps):
            self.steps[step_index]['status'] = status
            self.steps[step_index]['message'] = message
            self.progress = (step_index + 1) / len(self.steps) * 100
            
            status_icon = "âœ…" if status == 'completed' else "â³" if status == 'running' else "âŒ"
            print(f"{status_icon} {self.steps[step_index]['name']}: {message}")
    
    def get_progress_report(self) -> dict:
        """è·å–è¿›åº¦æŠ¥å‘Š"""
        elapsed_time = time.time() - self.start_time if self.start_time else 0
        completed_steps = sum(1 for step in self.steps if step['status'] == 'completed')
        
        return {
            'progress_percentage': self.progress,
            'completed_steps': completed_steps,
            'total_steps': len(self.steps),
            'elapsed_time': elapsed_time,
            'estimated_remaining': self.estimate_remaining_time(elapsed_time, completed_steps, len(self.steps)),
            'current_step': self.current_step,
            'step_details': self.steps
        }
    
    def estimate_remaining_time(self, elapsed: float, completed: int, total: int) -> float:
        """ä¼°ç®—å‰©ä½™æ—¶é—´"""
        if completed == 0:
            return 0
        avg_time_per_step = elapsed / completed
        remaining_steps = total - completed
        return avg_time_per_step * remaining_steps
```

### 4. ç›‘æ§å‘Šè­¦é…ç½®

#### 4.1 ç›‘æ§æŒ‡æ ‡é˜ˆå€¼è®¾ç½®
```python
class MonitoringThresholds:
    def __init__(self):
        self.thresholds = {
            'performance': {
                'file_load_time_ms': {
                    'warning': 1000,    # 1ç§’è­¦å‘Š
                    'critical': 5000    # 5ç§’ä¸¥é‡
                },
                'render_time_ms': {
                    'warning': 500,     # 500msè­¦å‘Š
                    'critical': 2000    # 2ç§’ä¸¥é‡
                },
                'memory_usage_mb': {
                    'warning': 200,     # 200MBè­¦å‘Š
                    'critical': 500     # 500MBä¸¥é‡
                }
            },
            'cache': {
                'hit_rate_percent': {
                    'warning': 70,      # 70%è­¦å‘Š
                    'critical': 50      # 50%ä¸¥é‡
                },
                'eviction_rate_percent': {
                    'warning': 20,      # 20%è­¦å‘Š
                    'critical': 40      # 40%ä¸¥é‡
                }
            },
            'errors': {
                'error_rate_percent': {
                    'warning': 5,       # 5%è­¦å‘Š
                    'critical': 15      # 15%ä¸¥é‡
                },
                'consecutive_failures': {
                    'warning': 3,       # è¿ç»­3æ¬¡å¤±è´¥è­¦å‘Š
                    'critical': 10      # è¿ç»­10æ¬¡å¤±è´¥ä¸¥é‡
                }
            }
        }
    
    def check_threshold(self, metric_name: str, value: float) -> dict:
        """æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦è¶…è¿‡é˜ˆå€¼"""
        # è§£ææŒ‡æ ‡è·¯å¾„ï¼Œå¦‚ 'performance.file_load_time_ms'
        path_parts = metric_name.split('.')
        current = self.thresholds
        
        try:
            for part in path_parts:
                current = current[part]
        except KeyError:
            return {'status': 'unknown', 'message': f'æœªçŸ¥æŒ‡æ ‡: {metric_name}'}
        
        if value >= current['critical']:
            return {
                'status': 'critical',
                'message': f'{metric_name} = {value} è¶…è¿‡ä¸¥é‡é˜ˆå€¼ {current["critical"]}'
            }
        elif value >= current['warning']:
            return {
                'status': 'warning',
                'message': f'{metric_name} = {value} è¶…è¿‡è­¦å‘Šé˜ˆå€¼ {current["warning"]}'
            }
        else:
            return {
                'status': 'normal',
                'message': f'{metric_name} = {value} åœ¨æ­£å¸¸èŒƒå›´å†…'
            }
```

#### 4.2 å‘Šè­¦è§„åˆ™é…ç½®
```python
class AlertRuleManager:
    def __init__(self):
        self.alert_rules = []
        self.alert_history = []
        
    def add_rule(self, rule: dict):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        required_fields = ['name', 'condition', 'severity', 'message']
        for field in required_fields:
            if field not in rule:
                raise ValueError(f"å‘Šè­¦è§„åˆ™ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        self.alert_rules.append(rule)
        print(f"å‘Šè­¦è§„åˆ™å·²æ·»åŠ : {rule['name']}")
    
    def evaluate_rules(self, metrics: dict) -> list:
        """è¯„ä¼°æ‰€æœ‰å‘Šè­¦è§„åˆ™"""
        triggered_alerts = []
        
        for rule in self.alert_rules:
            if self.evaluate_rule(rule, metrics):
                alert = {
                    'rule_name': rule['name'],
                    'severity': rule['severity'],
                    'message': rule['message'],
                    'timestamp': time.time(),
                    'metrics': metrics
                }
                triggered_alerts.append(alert)
                
                # è®°å½•å‘Šè­¦å†å²
                self.alert_history.append(alert)
        
        return triggered_alerts
    
    def evaluate_rule(self, rule: dict, metrics: dict) -> bool:
        """è¯„ä¼°å•ä¸ªå‘Šè­¦è§„åˆ™"""
        condition = rule['condition']
        
        # æ”¯æŒç®€å•çš„æ¡ä»¶è¡¨è¾¾å¼
        # æ ¼å¼: "metric_name operator value"
        # ä¾‹å¦‚: "file_load_time_ms > 1000"
        
        try:
            parts = condition.split()
            if len(parts) != 3:
                return False
            
            metric_name, operator, value_str = parts
            metric_value = metrics.get(metric_name, 0)
            threshold_value = float(value_str)
            
            if operator == '>':
                return metric_value > threshold_value
            elif operator == '<':
                return metric_value < threshold_value
            elif operator == '>=':
                return metric_value >= threshold_value
            elif operator == '<=':
                return metric_value <= threshold_value
            elif operator == '==':
                return metric_value == threshold_value
            elif operator == '!=':
                return metric_value != threshold_value
            else:
                return False
                
        except (ValueError, KeyError):
            return False
    
    def get_alert_history(self, hours: int = 24) -> list:
        """è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„å‘Šè­¦å†å²"""
        cutoff_time = time.time() - (hours * 3600)
        return [alert for alert in self.alert_history if alert['timestamp'] >= cutoff_time]
```

#### 4.3 å‘Šè­¦é€šçŸ¥æ¸ é“
```python
class AlertNotifier:
    def __init__(self):
        self.notification_channels = {}
        self.notification_history = []
        
    def add_channel(self, channel_name: str, channel_config: dict):
        """æ·»åŠ é€šçŸ¥æ¸ é“"""
        self.notification_channels[channel_name] = channel_config
        print(f"é€šçŸ¥æ¸ é“å·²æ·»åŠ : {channel_name}")
    
    def send_alert(self, alert: dict):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        notification = {
            'alert': alert,
            'timestamp': time.time(),
            'channels': []
        }
        
        for channel_name, channel_config in self.notification_channels.items():
            try:
                if self.send_to_channel(channel_name, channel_config, alert):
                    notification['channels'].append(channel_name)
            except Exception as e:
                print(f"å‘é€å‘Šè­¦åˆ°æ¸ é“ {channel_name} å¤±è´¥: {e}")
        
        self.notification_history.append(notification)
        return notification
    
    def send_to_channel(self, channel_name: str, config: dict, alert: dict) -> bool:
        """å‘é€å‘Šè­¦åˆ°æŒ‡å®šæ¸ é“"""
        if channel_name == 'console':
            return self.send_to_console(alert)
        elif channel_name == 'log':
            return self.send_to_log(config, alert)
        elif channel_name == 'email':
            return self.send_to_email(config, alert)
        elif channel_name == 'webhook':
            return self.send_to_webhook(config, alert)
        else:
            print(f"æœªçŸ¥çš„é€šçŸ¥æ¸ é“: {channel_name}")
            return False
    
    def send_to_console(self, alert: dict) -> bool:
        """å‘é€åˆ°æ§åˆ¶å°"""
        severity_icon = {
            'critical': 'ğŸš¨',
            'warning': 'âš ï¸',
            'info': 'â„¹ï¸'
        }
        
        icon = severity_icon.get(alert['severity'], 'â“')
        print(f"{icon} [{alert['severity'].upper()}] {alert['message']}")
        return True
    
    def send_to_log(self, config: dict, alert: dict) -> bool:
        """å‘é€åˆ°æ—¥å¿—æ–‡ä»¶"""
        log_file = config.get('log_file', 'alerts.log')
        log_format = config.get('format', 'json')
        
        try:
            with open(log_file, 'a', encoding='utf-8') as f:
                if log_format == 'json':
                    log_entry = {
                        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                        'severity': alert['severity'],
                        'message': alert['message'],
                        'rule_name': alert['rule_name']
                    }
                    f.write(json.dumps(log_entry) + '\n')
                else:
                    f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] "
                           f"[{alert['severity'].upper()}] "
                           f"{alert['message']}\n")
            return True
        except Exception as e:
            print(f"å†™å…¥æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
            return False
```

#### 4.4 å‘Šè­¦å‡çº§ç­–ç•¥
```python
class AlertEscalationManager:
    def __init__(self):
        self.escalation_rules = []
        self.escalation_history = []
        
    def add_escalation_rule(self, rule: dict):
        """æ·»åŠ å‡çº§è§„åˆ™"""
        required_fields = ['name', 'trigger_condition', 'escalation_action', 'delay_minutes']
        for field in required_fields:
            if field not in rule:
                raise ValueError(f"å‡çº§è§„åˆ™ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        self.escalation_rules.append(rule)
        print(f"å‡çº§è§„åˆ™å·²æ·»åŠ : {rule['name']}")
    
    def check_escalation(self, alerts: list) -> list:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦å‡çº§å‘Šè­¦"""
        escalation_actions = []
        
        for rule in self.escalation_rules:
            if self.should_escalate(rule, alerts):
                action = {
                    'rule_name': rule['name'],
                    'action': rule['escalation_action'],
                    'timestamp': time.time(),
                    'triggered_alerts': alerts
                }
                escalation_actions.append(action)
                
                # è®°å½•å‡çº§å†å²
                self.escalation_history.append(action)
        
        return escalation_actions
    
    def should_escalate(self, rule: dict, alerts: list) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å‡çº§"""
        condition = rule['trigger_condition']
        
        # æ£€æŸ¥å‘Šè­¦æ•°é‡
        if 'min_alert_count' in condition:
            if len(alerts) < condition['min_alert_count']:
                return False
        
        # æ£€æŸ¥å‘Šè­¦æŒç»­æ—¶é—´
        if 'min_duration_minutes' in condition:
            current_time = time.time()
            for alert in alerts:
                alert_age = (current_time - alert['timestamp']) / 60  # è½¬æ¢ä¸ºåˆ†é’Ÿ
                if alert_age < condition['min_duration_minutes']:
                    return False
        
        # æ£€æŸ¥å‘Šè­¦ä¸¥é‡ç¨‹åº¦
        if 'min_severity' in condition:
            severity_levels = {'info': 1, 'warning': 2, 'critical': 3}
            min_level = severity_levels.get(condition['min_severity'], 0)
            
            has_high_severity = any(
                severity_levels.get(alert['severity'], 0) >= min_level
                for alert in alerts
            )
            if not has_high_severity:
                return False
        
        return True
    
    def execute_escalation(self, escalation_action: dict):
        """æ‰§è¡Œå‡çº§åŠ¨ä½œ"""
        action = escalation_action['action']
        
        if action['type'] == 'notification':
            # å‘é€å‡çº§é€šçŸ¥
            self.send_escalation_notification(escalation_action)
        elif action['type'] == 'restart_service':
            # é‡å¯æœåŠ¡
            self.restart_service(action.get('service_name', 'markdown_renderer'))
        elif action['type'] == 'fallback_mode':
            # å¯ç”¨é™çº§æ¨¡å¼
            self.enable_fallback_mode()
        else:
            print(f"æœªçŸ¥çš„å‡çº§åŠ¨ä½œç±»å‹: {action['type']}")
    
    def send_escalation_notification(self, escalation: dict):
        """å‘é€å‡çº§é€šçŸ¥"""
        message = f"ğŸš¨ å‘Šè­¦å‡çº§è§¦å‘: {escalation['rule_name']}\n"
        message += f"è§¦å‘æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(escalation['timestamp']))}\n"
        message += f"å‘Šè­¦æ•°é‡: {len(escalation['triggered_alerts'])}\n"
        message += f"å‡çº§åŠ¨ä½œ: {escalation['action']}"
        
        print(message)
        # è¿™é‡Œå¯ä»¥é›†æˆå…·ä½“çš„é€šçŸ¥æ¸ é“ï¼ˆé‚®ä»¶ã€çŸ­ä¿¡ã€é’‰é’‰ç­‰ï¼‰
    
    def restart_service(self, service_name: str):
        """é‡å¯æœåŠ¡"""
        print(f"æ­£åœ¨é‡å¯æœåŠ¡: {service_name}")
        # è¿™é‡Œå®ç°å…·ä½“çš„æœåŠ¡é‡å¯é€»è¾‘
        
    def enable_fallback_mode(self):
        """å¯ç”¨é™çº§æ¨¡å¼"""
        print("æ­£åœ¨å¯ç”¨é™çº§æ¨¡å¼...")
        # è¿™é‡Œå®ç°å…·ä½“çš„é™çº§æ¨¡å¼å¯ç”¨é€»è¾‘
```

---

### 7. éªŒæ”¶æ¸…å•ï¼ˆè¿ç»´ï¼‰
- [ ] ç»“æ„åŒ–æ—¥å¿—è¾“å‡ºæ­£å¸¸ã€è½®è½¬ç”Ÿæ•ˆ
- [ ] å…³é”®æŒ‡æ ‡é‡‡é›†å¯ç”¨ã€é˜ˆå€¼å‘Šè­¦å¯è§¦å‘
- [ ] æ¸…ç†ç¼“å­˜/é‡è½½é…ç½®å¯ç”¨
- [ ] å›æ»šæ¼”ç»ƒå·²é€šè¿‡ï¼ˆ< 10 åˆ†é’Ÿæ¢å¤ï¼‰

---

## 13.4 é•¿æœŸæ€§èƒ½ä¼˜åŒ–ä¸ç¨³å®šæ€§æµ‹è¯•ï¼ˆé•¿æœŸä¼˜åŒ–ï¼‰

### 1. ä¼šè¯å…ƒæ•°æ®
- ä¼šè¯ID: 2025-08-15-16-24-41
- æ–‡æ¡£ç±»å‹: é•¿æœŸä¼˜åŒ–ä¸ç¨³å®šæ€§æµ‹è¯•è¡¥å……

### 2. 3â€“6 ä¸ªæœˆè·¯çº¿å›¾ï¼ˆQuarter Roadmapï¼‰
- æœˆ1ï¼šå®Œæˆæµå¼/åˆ†å—è¯»å– + æ¸²æŸ“å™¨é€‰æ‹©ç¼“å­˜åŒ– + é“¾æ¥å¤„ç†ç¼“å­˜
- æœˆ2ï¼šå¼•å…¥å†…å­˜æ˜ å°„ï¼ˆmmapï¼‰ä¸å¤§æ–‡ä»¶åˆ†æ®µç´¢å¼•ï¼›ç›‘æ§é¢æ¿å¯è§†åŒ–
- æœˆ3ï¼šç¨³å®šæ€§ä¸éŸ§æ€§æµ‹è¯•ï¼ˆæ•…éšœæ³¨å…¥ã€é•¿ç¨³å‹æµ‹ï¼‰ï¼›UI äº‹ä»¶æ‰¹å¤„ç†ä¼˜åŒ–
- æœˆ4â€“6ï¼šç®—æ³•çº§ä¼˜åŒ–ï¼ˆæ¨¡æ¿æ¸²æŸ“ã€çŸ¢é‡åŒ–å¤„ç†ï¼‰ä¸è·¨è¿›ç¨‹å¹¶è¡Œæ¸²æŸ“ï¼ˆå¯é€‰ï¼‰

### 3. æ·±åº¦æ€§èƒ½ä¼˜åŒ–

#### 3.1 æµå¼/åˆ†å—æ¸²æŸ“
- ç›®æ ‡ï¼š10MB+ è¶…å¤§æ–‡ä»¶é¦–å±å¯åœ¨ < 2s å‘ˆç°
- åšæ³•ï¼š
	- åˆ†å—è¯»å–ï¼ˆ1MBï¼‰â†’ è¡Œç¼“å†²æ‹¼æ¥ â†’ å¢é‡æ¸²æŸ“ï¼ˆæ®µè½/é¡µï¼‰
	- UI çº¿ç¨‹ä»…æ¥æ”¶ HTML ç‰‡æ®µï¼ˆQWebEngineView çš„ append/replaceï¼‰

#### 3.2 å†…å­˜ä¼˜åŒ–
- ä½¿ç”¨ `mmap` è¿›è¡Œåªè¯»æ˜ å°„ï¼Œé¿å…æ•´ä½“æ‹·è´
- å¤§å¯¹è±¡æ± åŒ–ã€å¤ç”¨ StringBuilderï¼›å›¾ç‰‡ç¼©ç•¥å›¾/å»¶è¿ŸåŠ è½½
- ç¼“å­˜æŒ‰â€œå†…å®¹ç±»å‹æƒé‡â€åˆ†å±‚ï¼ˆæ–‡æœ¬ä¼˜å…ˆã€å›¾ç‰‡ä»…ç¼©ç•¥ï¼‰

#### 3.3 ç®—æ³•ä¸æ¨¡æ¿
- ç»Ÿä¸€ HTML æ¨¡æ¿ï¼ˆå‡å°‘å­—ç¬¦ä¸²æ‹¼æ¥ï¼‰
- æ‰¹é‡è¡Œå·ç”Ÿæˆã€æ‰¹é‡ escapeï¼ˆå‘é‡åŒ– / C æ‰©å±•å¯é€‰ï¼‰
- è¯­æ³•é«˜äº®é‡‡ç”¨é¢„ç¼–è¯‘æ–¹æ¡ˆï¼ˆå¦‚ Pygments é¢„ç”Ÿæˆï¼‰

### 4. ç¨³å®šæ€§ä¸éŸ§æ€§æµ‹è¯•

#### 4.1 æ•…éšœæ³¨å…¥ï¼ˆChaosï¼‰
- æ¨¡æ‹Ÿï¼š
	- æ–‡ä»¶æƒé™æ‹’ç»/è·¯å¾„ä¸å­˜åœ¨
	- ç¼–ç æ¢æµ‹å¤±è´¥/è¯»å–è¶…æ—¶
	- å¤–éƒ¨æ¨¡å—å¯¼å…¥å¤±è´¥/ç¬¦å·ç¼ºå¤±
- æœŸæœ›ï¼š
	- å¯æ¢å¤é”™è¯¯è‡ªåŠ¨é‡è¯•å¹¶æˆåŠŸ
	- ä¸å¯æ¢å¤é”™è¯¯å¿«é€Ÿé™çº§ + å‹å¥½æç¤º
	- é”™è¯¯é“¾è·¯æ—¥å¿—å®Œæ•´å¯è¿½è¸ª

#### 4.2 å‹æµ‹ä¸ç–²åŠ³æµ‹è¯•ï¼ˆSoakï¼‰
- è¿ç»­ 24â€“72 å°æ—¶å¾ªç¯æ‰“å¼€/æ¸²æŸ“/å…³é—­ä¸åŒå¤§å°æ–‡ä»¶
- æŒ‡æ ‡ï¼šå†…å­˜æ³„æ¼ï¼ˆRSS è¶‹åŠ¿ï¼‰ã€æ¸²æŸ“æˆåŠŸç‡ã€å¹³å‡å“åº”æ—¶é—´
- é€šè¿‡æ ‡å‡†ï¼š
	- RSS ç¨³å®šæˆ–ç¼“æ…¢ä¸Šå‡ä¸”å‘¨æœŸæ€§å›è½ï¼ˆGC/ç¼“å­˜æ¸…ç†ç”Ÿæ•ˆï¼‰
	- æˆåŠŸç‡ â‰¥ 99.9%
	- å“åº”æ—¶é—´æ— é˜¶è·ƒå›é€€

#### 4.3 å›å½’ä¸å¯¹æ¯”
- å¯¹æ¯”å…³é”®è·¯å¾„ï¼ˆæ¸²æŸ“ã€é¢„è§ˆã€å¯¼å…¥ï¼‰åœ¨ 3 ä¸ªç‰ˆæœ¬çš„è¡¨ç°
- ä»…å½“ 95 ç™¾åˆ†ä½å“åº”æ—¶é—´ä¸å›é€€æ‰å…è®¸å‘å¸ƒ

### 5. åº¦é‡ä¸å·¥å…·
- cProfile + snakevizï¼šå‡½æ•°çº§çƒ­ç‚¹
- memory_profilerï¼šå³°å€¼ä¸æ³„æ¼è¶‹åŠ¿
- pytest-benchmarkï¼šåŸºå‡†å¯¹æ¯”
- è‡ªå®šä¹‰æŒ‡æ ‡ï¼š
	- renderer_choiceã€fallback_usedã€import_elapsed_ms
	- file_read_msã€render_msã€cache_hit

### 6. å‘å¸ƒé—¨æ§›ï¼ˆé•¿ç¨³ï¼‰
- Soak æµ‹è¯• 24h é€šè¿‡ï¼Œé”™è¯¯ç‡ < 0.1%
- å…³é”®æŒ‡æ ‡ 95P ä¸å›é€€ï¼›å¹³å‡æ€§èƒ½æå‡ â‰¥10%
- é“¾æ¥å¤„ç†ç¨³å®šï¼ˆé”™è¯¯éš”ç¦» + é™çº§å¯éªŒè¯ï¼‰
- ç›‘æ§ä¸å‘Šè­¦å…¨éƒ¨ç”Ÿæ•ˆ

---

### 7. æŒç»­æ”¹è¿›
- æ¯æœˆä¸€æ¬¡åŸºçº¿æ›´æ–°ä¸å¤æµ‹
- å…¸å‹ç”¨æˆ·æ ·æœ¬åº“æŒç»­æ‰©å……
- å½¢æˆä¼˜åŒ–æ‰‹å†Œä¸æœ€ä½³å®è·µï¼Œçº³å…¥ä»£ç å®¡æŸ¥æ¸…å•

---

## 13.A é™„å½•-æŠ€æœ¯æ·±æŒ–ï¼ˆå¼•ç”¨ä¸èŒƒå›´æ ‡æ³¨ï¼‰
- é™„å½•æ¥æºï¼š`æ–¹æ¡ˆ4-æ··åˆæ¶æ„ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡-æŠ€æœ¯å®ç°ç»†èŠ‚è¡¥å…….md`
- ä½œç”¨ï¼šæä¾›æ›´æ·±å…¥çš„å®ç°è‰æ¡ˆä¸åŸå‹ï¼ˆé‡è¯•/é™çº§ã€æ€§èƒ½æ¡†æ¶ç­‰ï¼‰ï¼Œä¸ºåç»­æ‰©å±•æä¾›å‚è€ƒã€‚

### A.1 å¯ç›´æ¥å¼•ç”¨çš„å®ç°ç‰‡æ®µï¼ˆå»ºè®®æŒ‰éœ€é‡‡çº³ï¼‰
- æ™ºèƒ½é‡è¯•æœºåˆ¶ï¼š`SmartRetryMechanism`ï¼ˆæŒ‡æ•°/çº¿æ€§/æŠ–åŠ¨/è‡ªé€‚åº”é€€é¿ã€æˆåŠŸç‡ç»Ÿè®¡ï¼‰
- ä¼˜é›…é™çº§ç®¡ç†ï¼š`GracefulDegradationManager`ï¼ˆå¥åº·æ£€æŸ¥ã€ç­–ç•¥æ‰§è¡Œã€ç»Ÿè®¡ï¼‰
- æ€§èƒ½åŸºå‡†æ¡†æ¶ï¼š`PerformanceBenchmarkFramework` ä¸ `PerformanceTestScenarios`

### A.2 æ˜ç¡®æ ‡æ³¨ä¸ºâ€œè¶…å‡ºå½“å‰èŒƒå›´â€çš„å†…å®¹ï¼ˆåç»­é€‰é¡¹ï¼‰
- åˆ†å¸ƒå¼ç¼“å­˜ä¸€è‡´æ€§ä¸ç‰ˆæœ¬å‘é‡ï¼š`DistributedCacheManager`ï¼ˆå¼º/æœ€ç»ˆ/å¼±ä¸€è‡´æ€§ï¼‰
- é«˜çº§ç¼“å­˜å¤±æ•ˆå™¨ä¸åˆ†å¸ƒå¼é€šçŸ¥ï¼š`AdvancedCacheInvalidator`
è¯´æ˜ï¼šä¸Šè¿°åˆ†å¸ƒå¼èƒ½åŠ›ä¸å±äºâ€œæœ¬åœ° Markdown æ¸²æŸ“ç¨‹åºâ€å½“å‰èŒƒå›´ï¼Œä¿ç•™ä¸ºæœªæ¥æ¼”è¿›é€‰é¡¹ã€‚

### A.3 ä¸ LinkProcessor çš„é›†æˆé’©å­ï¼ˆå ä½ï¼‰
- åœ¨ `HybridMarkdownRenderer` æ¸²æŸ“å®Œæˆåï¼Œå¯¹ HTML è¿›è¡Œé“¾æ¥åå¤„ç†ï¼ˆå¯æ’æ‹”ï¼‰
- åœ¨ `ContentPreview` å„ `_generate_*_html()` é˜¶æ®µæä¾›é“¾æ¥å¤„ç†å‰/åç½®é’©å­
- æŒ‡æ ‡æ‰“ç‚¹ï¼š`links_processed_count`ã€`link_resolve_ms`ã€`link_cache_hit`

---

## 13.7 æ³¨é‡Šç¤ºä¾‹çš„ä½¿ç”¨è¯´æ˜ï¼ˆæ–°å¢ï¼‰
- ä½œç”¨ï¼š
  - ä¸ºå¼€å‘è€…æä¾›æœ€å°å¼•ç”¨èŒƒå¼ï¼ˆç»Ÿä¸€å¼‚å¸¸/é€šé…åˆ é™¤å·¥å…·ï¼‰ï¼Œå‡å°‘è®¤çŸ¥æˆæœ¬
  - ä½œä¸ºä»£ç å®¡æŸ¥ä¸å®ç°å¯¹é½çš„â€œå‚ç…§ç‰©â€ï¼Œé¿å…é£æ ¼ä¸ä¸€è‡´
- å½¢å¼ï¼š
  - ä»…ä»¥â€œæ–‡æ¡£æ³¨é‡Šï¼šå¼•ç”¨ç¤ºä¾‹ï¼ˆä»…ä¾›å‚è€ƒï¼Œéè¿è¡Œä»£ç ï¼‰â€å­˜åœ¨äºæ ¸å¿ƒæ¨¡å—æ–‡ä»¶å°¾éƒ¨
  - ä¸å‚ä¸è¿è¡Œã€ä¸æ³¨å…¥é€»è¾‘ã€ä¸å½±å“æµ‹è¯•
- å‡ºç°ä½ç½®ï¼š
  - `core/markdown_renderer.py`ã€`core/link_processor.py`ã€`core/content_preview.py` æ–‡ä»¶å°¾éƒ¨
- ä½¿ç”¨æ–¹å¼ï¼š
  - å®ç°æ—¶â€œå¯¹ç…§â€æ³¨é‡Šç¤ºä¾‹ï¼Œå¤åˆ¶å¿…è¦çš„ import ä¸è°ƒç”¨æ–¹å¼ï¼Œå¹¶æ›¿æ¢ä¸ºçœŸå®å˜é‡ä¸é€»è¾‘
  - è‹¥é¡¹ç›®æä¾›äº†æ›´å®Œå¤‡çš„é€‚é…å±‚ï¼ˆä¾‹å¦‚ç»Ÿä¸€ Cache é€‚é…å™¨ï¼‰ï¼Œå¯å¿½ç•¥ç¤ºä¾‹ä¸­çš„å·¥å…·å‡½æ•°
- ä¸AIäº¤äº’çš„æ³¨æ„äº‹é¡¹ï¼š
  - æ˜ç¡®è¯¥ç±»æ³¨é‡Šä¸ºâ€œå‚è€ƒæ¨¡æ¿â€ï¼ŒAI åœ¨ç”Ÿæˆä»£ç æ—¶åº”ä½œä¸ºâ€œèŒƒå¼æç¤ºâ€è€Œéç›´æ¥æ³¨å…¥
  - å½“ç›®æ ‡æ¨¡å—å·²æœ‰å…·ä½“å®ç°æ—¶ï¼Œä¼˜å…ˆéµå¾ªç°æœ‰æ¥å£ä¸çº¦æŸï¼Œä¸å¼ºåˆ¶å¼•å…¥ç¤ºä¾‹ä¸­çš„å·¥å…·/å¼‚å¸¸

---

## 13.5 é€‚ç”¨ä¸æ‰§è¡Œ
- æœ¬ç« èšåˆè§†å›¾ç”¨äºâ€œå®æ–½é˜¶æ®µâ€çš„è½åœ°æ‰§è¡Œï¼Œåˆ†åˆ«å¯¹åº”ï¼š
  - ç«‹å³è¡¥å……ï¼ˆ13.2ï¼‰ï¼šå¼€å‘ç›´æ¥é‡‡çº³
  - çŸ­æœŸå®Œå–„ï¼ˆ13.3ï¼‰ï¼šéƒ¨ç½²ä¸Šçº¿ä¸è¿ç»´é—­ç¯
  - é•¿æœŸä¼˜åŒ–ï¼ˆ13.4ï¼‰ï¼šè·¯çº¿å›¾ä¸é—¨æ§›
- é™„å½•ï¼ˆ13.Aï¼‰ä»…ä½œæŠ€æœ¯å‚¨å¤‡ï¼Œåˆ†å¸ƒå¼ç›¸å…³ä¿ç•™ä¸ºåç»­é€‰é¡¹

## 13.6 ä¸Šçº¿è½åœ°æ¸…å•ï¼ˆChecklistï¼‰
- é…ç½®
  - [ ] `link_processor.enabled`/`link_processor.module` å·²é…ç½®
  - [ ] `markdown.use_dynamic_import`/`markdown.fallback_enabled` æ ¡éªŒ
  - [ ] `content_viewer.cache_limit`ã€`logging.level` åˆç†
- ç¼“å­˜
  - [ ] `UnifiedCacheManager` å·²åŒ…å« link/validation/resolution/renderer_selection å‘½åç©ºé—´
  - [ ] æ–‡ä»¶/å†…å®¹/æ¸²æŸ“é”®ç­–ç•¥ä¸å¤±æ•ˆæœºåˆ¶éªŒè¯
  - [ ] é“¾æ¥ç¼“å­˜å¤±æ•ˆï¼ˆæ–‡ä»¶å˜æ›´ã€åŸŸå¤±æ•ˆï¼‰éªŒè¯
- é”™è¯¯å¤„ç†
  - [ ] `ErrorType`/`ErrorSeverity` æšä¸¾å¯¹é½
  - [ ] é»˜è®¤å¤„ç†å™¨å¤„ç† `UNKNOWN_ERROR`
  - [ ] é‡è¯•/é™çº§è·¯å¾„è§¦å‘ä¸æ—¥å¿—å¯è¿½è¸ª
- æ€§èƒ½
  - [ ] åŸºçº¿æµ‹è¯•ï¼ˆå°/ä¸­/å¤§/è¶…å¤§ï¼‰é€šè¿‡
  - [ ] 95P ä¸å›é€€ï¼›å›å½’ç”¨ä¾‹æ— ä¸¥é‡å›é€€
  - [ ] ç›‘æ§é˜ˆå€¼ä¸å‘Šè­¦å¼€é€š
- ç›‘æ§ä¸æ—¥å¿—
  - [ ] ç»“æ„åŒ–æ—¥å¿—è¾“å‡ºä¸è½®è½¬ç”Ÿæ•ˆ
  - [ ] æŒ‡æ ‡ï¼šfile_read_ms/render_ms/cache_hit/links_processed_count
  - [ ] ä»ªè¡¨æ¿å¯ç”¨ï¼Œå¼‚å¸¸æœ‰å‘Šè­¦
- å›æ»šä¸è¿ç»´
  - [ ] å›æ»šç‚¹åˆ›å»ºå¹¶æ¼”ç»ƒï¼ˆ<10åˆ†é’Ÿï¼‰
  - [ ] è‡ªæ£€è„šæœ¬é€šè¿‡ï¼ˆé…ç½®/æ—¥å¿—ç›®å½•å¯å†™ï¼‰
  - [ ] ç¼“å­˜æ¸…ç†/é…ç½®é‡è½½æŒ‡ä»¤å¯ç”¨