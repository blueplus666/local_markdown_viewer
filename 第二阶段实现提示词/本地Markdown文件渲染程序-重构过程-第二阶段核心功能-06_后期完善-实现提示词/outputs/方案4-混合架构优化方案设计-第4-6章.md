# 方案4-混合架构优化方案设计-第4-6章

## 4. 缓存机制优化

### 4.1 统一缓存管理架构

**当前缓存问题**：
- 三个独立缓存系统：渲染缓存、导入缓存、内容缓存
- 缓存策略不一致，缺乏协调
- 内存使用不优化，可能重复缓存相同内容

**统一缓存管理器设计**：
```python
class UnifiedCacheManager:
    def __init__(self):
        self.caches = {
            'render': LRUCache(max_size=100, ttl=3600),      # 渲染缓存，1小时过期
            'content': LRUCache(max_size=50, ttl=1800),      # 内容缓存，30分钟过期
            'import': LRUCache(max_size=20, ttl=7200),       # 导入缓存，2小时过期
            'file_info': LRUCache(max_size=200, ttl=900),    # 文件信息缓存，15分钟过期
            'encoding': LRUCache(max_size=100, ttl=3600)     # 编码检测缓存，1小时过期
        }
        self.global_stats = CacheStats()
    
    def get_cache(self, cache_type: str) -> Optional[LRUCache]:
        return self.caches.get(cache_type)
    
    def get_global_stats(self) -> Dict[str, Any]:
        return self.global_stats.get_stats()
    
    def clear_all(self) -> None:
        for cache in self.caches.values():
            cache.clear()
        self.global_stats.reset()
```

**智能缓存键生成**：
```python
class SmartCacheKey:
    @staticmethod
    def for_render(content: str, options: Dict[str, Any]) -> str:
        # 基于内容和关键选项生成缓存键
        key_data = {
            'content_hash': hashlib.sha256(content.encode()).hexdigest()[:16],
            'options_hash': hashlib.md5(json.dumps(options, sort_keys=True).encode()).hexdigest()[:8]
        }
        return f"render:{key_data['content_hash']}:{key_data['options_hash']}"
    
    @staticmethod
    def for_file(file_path: Path, file_info: Dict[str, Any]) -> str:
        # 基于文件路径和修改时间生成缓存键
        mtime = file_info.get('modified_time', 0)
        return f"file:{file_path.absolute()}:{mtime}"
```

### 4.2 缓存失效策略优化

**基于文件修改时间的失效**：
```python
class FileBasedCacheInvalidator:
    def __init__(self, cache_manager: UnifiedCacheManager):
        self.cache_manager = cache_manager
        self.file_watchers = {}
    
    def watch_file(self, file_path: Path, cache_keys: List[str]):
        """监听文件变化，自动失效相关缓存"""
        if file_path not in self.file_watchers:
            self.file_watchers[file_path] = FileWatcher(file_path)
        
        self.file_watchers[file_path].add_cache_keys(cache_keys)
    
    def invalidate_file_caches(self, file_path: Path):
        """文件变化时失效所有相关缓存"""
        if file_path in self.file_watchers:
            cache_keys = self.file_watchers[file_path].get_cache_keys()
            for cache_type in ['render', 'content', 'file_info']:
                cache = self.cache_manager.get_cache(cache_type)
                if cache:
                    for key in cache_keys:
                        cache.delete(key)
```

**智能内存管理**：
```python
class MemoryAwareCache:
    def __init__(self, max_size: int, max_memory_mb: int):
        self.max_size = max_size
        self.max_memory_bytes = max_memory_mb * 1024 * 1024
        self.current_memory = 0
        self.cache = {}
        self.access_order = []
    
    def set(self, key: str, value: Any) -> bool:
        # 估算值的内存占用
        estimated_size = self._estimate_size(value)
        
        # 如果单个值太大，拒绝缓存
        if estimated_size > self.max_memory_bytes * 0.1:  # 单个值不超过总内存的10%
            return False
        
        # 如果超出内存限制，清理最旧的缓存
        while (self.current_memory + estimated_size > self.max_memory_bytes and 
               len(self.cache) > 0):
            self._evict_oldest()
        
        # 设置缓存
        if key in self.cache:
            self.current_memory -= self._estimate_size(self.cache[key])
        
        self.cache[key] = value
        self.current_memory += estimated_size
        self._update_access_order(key)
        
        return True
```

## 5. 错误处理优化

### 5.1 统一错误处理框架

**错误分类体系**：
```python
class ErrorType(Enum):
    # 文件相关错误
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_READ_ERROR = "FILE_READ_ERROR"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    ENCODING_ERROR = "ENCODING_ERROR"
    
    # 渲染相关错误
    RENDER_ERROR = "RENDER_ERROR"
    MODULE_IMPORT_ERROR = "MODULE_IMPORT_ERROR"
    RENDERER_UNAVAILABLE = "RENDERER_UNAVAILABLE"
    
    # 配置相关错误
    CONFIG_ERROR = "CONFIG_ERROR"
    CONFIG_VALIDATION_ERROR = "CONFIG_VALIDATION_ERROR"
    
    # 系统相关错误
    MEMORY_ERROR = "MEMORY_ERROR"
    PERMISSION_ERROR = "PERMISSION_ERROR"
    UNKNOWN_ERROR = "UNKNOWN_ERROR"

class ErrorSeverity(Enum):
    LOW = "LOW"           # 不影响主要功能
    MEDIUM = "MEDIUM"     # 部分功能受影响
    HIGH = "HIGH"         # 主要功能受影响
    CRITICAL = "CRITICAL" # 系统无法运行
```

**结构化错误结果**：
```python
@dataclass
class ErrorResult:
    success: bool = False
    error_type: ErrorType = ErrorType.UNKNOWN_ERROR
    error_code: str = ""
    message: str = ""
    details: Dict[str, Any] = None
    severity: ErrorSeverity = ErrorSeverity.MEDIUM
    timestamp: float = 0.0
    context: Dict[str, Any] = None
    stack_trace: str = ""
    can_retry: bool = False
    retry_count: int = 0
    max_retries: int = 3
    fallback_result: Any = None
```

### 5.2 错误传播优化

**错误传播链设计**：
```python
class ErrorPropagationChain:
    def __init__(self):
        self.error_handlers = {}
        self.error_contexts = {}
    
    def register_handler(self, error_type: ErrorType, handler: BaseErrorHandler):
        """注册错误处理器"""
        self.error_handlers[error_type] = handler
    
    def propagate_error(self, error: Exception, context: Dict[str, Any], 
                       propagation_path: List[str]) -> ErrorResult:
        """错误传播处理"""
        # 记录错误传播路径
        error_id = str(uuid.uuid4())
        self.error_contexts[error_id] = {
            'error': error,
            'context': context,
            'propagation_path': propagation_path,
            'timestamp': datetime.now()
        }
        
        # 尝试找到专门的错误处理器
        error_code = self._classify_error(error)
        if error_code in self.error_handlers:
            handler = self.error_handlers[error_code]
            return handler.handle_error(error, context)
        
        # 使用默认错误处理器
        default_handler = self.error_handlers.get(ErrorType.SYSTEM_ERROR)
        if default_handler:
            return default_handler.handle_error(error, context)
        
        # 创建基本错误结果
        return ErrorResult(
            error_code=error_code,
            error_message=str(error),
            context=context
        )
```

### 5.3 降级策略

**渲染器降级策略**：
```python
class RendererFallbackStrategy:
    def __init__(self):
        self.renderers = []
        self.current_index = 0
    
    def add_renderer(self, renderer: Any, priority: int):
        self.renderers.append((priority, renderer))
        self.renderers.sort(key=lambda x: x[0])
    
    def get_next_renderer(self) -> Optional[Any]:
        if self.current_index < len(self.renderers):
            renderer = self.renderers[self.current_index][1]
            self.current_index += 1
            return renderer
        return None
    
    def reset(self):
        self.current_index = 0
```

## 6. 性能优化

### 6.1 计算优化

**渲染器选择优化**：
```python
class RendererSelectionOptimizer:
    def __init__(self, cache_manager: UnifiedCacheManager):
        self.cache_manager = cache_manager
        self.renderer_cache = {}
        self.renderer_performance = {}
        self.last_selection_time = {}
    
    def preload_renderers(self):
        """预加载所有可用的渲染器"""
        renderers = [
            'markdown_processor',
            'markdown_library',
            'text_fallback'
        ]
        
        for renderer in renderers:
            try:
                if renderer == 'markdown_processor':
                    # 尝试动态导入
                    result = self._try_import_markdown_processor()
                    if result['success']:
                        self.renderer_cache[renderer] = result
                        self.renderer_performance[renderer] = 1.0
                elif renderer == 'markdown_library':
                    # 检查标准库
                    try:
                        import markdown
                        self.renderer_cache[renderer] = {'module': markdown}
                        self.renderer_performance[renderer] = 0.8
                    except ImportError:
                        pass
                elif renderer == 'text_fallback':
                    # 文本降级总是可用
                    self.renderer_cache[renderer] = {'available': True}
                    self.renderer_performance[renderer] = 0.5
            except Exception as e:
                logging.warning(f"Failed to preload renderer {renderer}: {e}")
    
    def select_renderer(self, content: str, options: Dict[str, Any]) -> str:
        """智能选择渲染器"""
        cache_key = f"renderer_selection:{hashlib.md5(content.encode()).hexdigest()[:16]}"
        
        # 检查缓存
        cached_selection = self.cache_manager.get('renderer_selection', cache_key)
        if cached_selection:
            return cached_selection
        
        # 基于性能和内容特征选择
        best_renderer = self._select_best_renderer(content, options)
        
        # 缓存选择结果
        self.cache_manager.set('renderer_selection', cache_key, best_renderer, ttl=300)  # 5分钟缓存
        
        return best_renderer
```

### 6.2 内存优化

**流式处理实现**：
```python
class StreamingFileProcessor:
    def __init__(self, chunk_size: int = 1024 * 1024):  # 1MB chunks
        self.chunk_size = chunk_size
    
    def process_file_streaming(self, file_path: Path, processor: Callable) -> Generator:
        with open(file_path, 'rb') as f:
            while True:
                chunk = f.read(self.chunk_size)
                if not chunk:
                    break
                yield processor(chunk)
    
    def render_markdown_streaming(self, file_path: Path) -> Generator:
        def process_chunk(chunk: bytes) -> str:
            # 处理单个chunk
            content = chunk.decode('utf-8', errors='replace')
            return self.markdown_renderer.render_chunk(content)
        
        return self.process_file_streaming(file_path, process_chunk)
```

### 6.3 I/O优化

**异步文件读取**：
```python
import asyncio
import aiofiles

class AsyncFileReader:
    def __init__(self):
        self._read_cache = {}
        self._max_cache_size = 100
    
    async def read_file_async(self, file_path: Path) -> str:
        # 检查缓存
        cache_key = str(file_path)
        if cache_key in self._read_cache:
            return self._read_cache[cache_key]
        
        # 异步读取文件
        try:
            async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                content = await f.read()
                
                # 缓存结果
                self._cache_result(cache_key, content)
                return content
                
        except Exception as e:
            raise FileReadError(f"Failed to read file {file_path}: {e}")
    
    async def read_file_chunked_async(self, file_path: Path, chunk_size: int = 1024 * 1024):
        async with aiofiles.open(file_path, 'rb') as f:
            while True:
                chunk = await f.read(chunk_size)
                if not chunk:
                    break
                yield chunk
```

---

**文件状态**: 第4-6章完成 ✅  
**内容行数**: 约480行  
**下一步**: 生成第7章-可观测性增强 